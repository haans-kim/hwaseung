import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from app.services.data_service import data_service

class DashboardService:
    def __init__(self):
        self.scenario_templates = {
            "base": {
                "name": "ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤",
                "description": "í˜„ì¬ ê²½ì œ ìƒí™© ê¸°ì¤€",
                "variables": {
                    "operating_income": 5.2,
                    "ev_growth_gl": 8.5,
                    "exchange_rate_change_krw": 2.3,
                    "labor_costs": 4.8,
                    "v_growth_gl": 7.2
                }
            },
            "optimistic": {
                "name": "ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ê³ ì„±ì¥ + ìˆ˜ìµì„± ê°œì„ ",
                "variables": {
                    "operating_income": 15.0,
                    "ev_growth_gl": 20.0,
                    "exchange_rate_change_krw": 5.0,
                    "labor_costs": 8.0,
                    "v_growth_gl": 18.0
                }
            },
            "moderate": {
                "name": "ì¤‘ë¦½ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ì•ˆì •ì  ì„±ì¥",
                "variables": {
                    "operating_income": 8.0,
                    "ev_growth_gl": 12.0,
                    "exchange_rate_change_krw": 3.5,
                    "labor_costs": 6.0,
                    "v_growth_gl": 10.0
                }
            },
            "pessimistic": {
                "name": "ë¹„ê´€ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ì €ì„±ì¥ + ìˆ˜ìµì„± ì•…í™”",
                "variables": {
                    "operating_income": -5.0,
                    "ev_growth_gl": 2.0,
                    "exchange_rate_change_krw": -2.0,
                    "labor_costs": 2.0,
                    "v_growth_gl": 1.5
                }
            }
        }
        
        self.variable_definitions = {
            "operating_income": {
                "name": "ì˜ì—…ì´ìµ",
                "description": "ì „ë…„ ëŒ€ë¹„ ì˜ì—…ì´ìµ ì¦ê°€ìœ¨ (%)",
                "min_value": -20.0,
                "max_value": 30.0,
                "unit": "%",
                "current_value": 5.2
            },
            "ev_growth_gl": {
                "name": "ê¸°ì—…ê°€ì¹˜ ì„±ì¥ë¥ ",
                "description": "ê¸€ë¡œë²Œ ê¸°ì—…ê°€ì¹˜ ì¦ê°€ìœ¨ (%)",
                "min_value": -15.0,
                "max_value": 25.0,
                "unit": "%",
                "current_value": 8.5
            },
            "exchange_rate_change_krw": {
                "name": "í™˜ìœ¨ ë³€ë™ë¥ ",
                "description": "ì›ë‹¬ëŸ¬ í™˜ìœ¨ ë³€ë™ë¥  (%)",
                "min_value": -10.0,
                "max_value": 15.0,
                "unit": "%",
                "current_value": 2.3
            },
            "labor_costs": {
                "name": "ì¸ê±´ë¹„",
                "description": "ì´ ì¸ê±´ë¹„ ì¦ê°€ìœ¨ (%)",
                "min_value": 0.0,
                "max_value": 20.0,
                "unit": "%",
                "current_value": 4.8
            },
            "v_growth_gl": {
                "name": "ë§¤ì¶œ ì„±ì¥ë¥ ",
                "description": "ê¸€ë¡œë²Œ ë§¤ì¶œ ì„±ì¥ë¥  (%)",
                "min_value": -10.0,
                "max_value": 25.0,
                "unit": "%",
                "current_value": 7.2
            }
        }
    
    def _prepare_model_input(self, variables: Dict[str, float]) -> pd.DataFrame:
        """ëª¨ë¸ ì…ë ¥ìš© ë°ì´í„° ì¤€ë¹„ - PyCaret ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •"""
        try:
            # PyCaret ëª¨ë¸ì˜ feature names ê°€ì ¸ì˜¤ê¸°
            from app.services.modeling_service import modeling_service
            from pycaret.regression import get_config
            
            # PyCaret ì„¤ì •ì—ì„œ feature ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                # ë¨¼ì € ëª¨ë¸ë§ ì„œë¹„ìŠ¤ì—ì„œ feature names ê°€ì ¸ì˜¤ê¸° (ê°€ì¥ ì •í™•í•¨)
                if hasattr(modeling_service, 'feature_names') and modeling_service.feature_names:
                    feature_columns = modeling_service.feature_names
                    print(f"âœ… Using feature names from modeling_service: {len(feature_columns)} features")
                else:
                    # PyCaret configì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                    X_train = get_config('X_train')
                    if X_train is not None:
                        feature_columns = list(X_train.columns)
                        print(f"âœ… Using feature names from PyCaret config: {len(feature_columns)} features")
                    else:
                        # ê¸°ë³¸ feature ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
                        feature_columns = [
                            'gdp_growth_kr', 'cpi_kr', 'unemployment_rate_kr', 'minimum_wage_increase_kr',
                            'gdp_growth_usa', 'cpi_usa', 'esi_usa', 'exchange_rate_change_krw',
                            'revenue_growth_sbl', 'op_profit_growth_sbl', 'labor_cost_rate_sbl',
                            'labor_cost_ratio_change_sbl', 'labor_cost_per_employee_sbl', 'labor_to_revenue_sbl',
                            'revenue_per_employee_sbl', 'op_profit_per_employee_sbl', 'hcroi_sbl', 'hcva_sbl',
                            'wage_increase_ce', 'revenue_growth_ce', 'op_profit_growth_ce', 'hcroi_ce', 'hcva_ce',
                            'market_size_growth_rate', 'compensation_competitiveness', 'wage_increase_bu_group',
                            'wage_increase_mi_group', 'wage_increase_total_group', 'public_sector_wage_increase'
                        ]
                        print(f"âš ï¸ Using default feature list: {len(feature_columns)} features")
            except Exception as e:
                print(f"Warning: Could not get PyCaret config: {e}")
                # ê¸°ë³¸ feature ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
                feature_columns = [
                    'gdp_growth_kr', 'cpi_kr', 'unemployment_rate_kr', 'minimum_wage_increase_kr',
                    'gdp_growth_usa', 'cpi_usa', 'esi_usa', 'exchange_rate_change_krw',
                    'revenue_growth_sbl', 'op_profit_growth_sbl', 'labor_cost_rate_sbl',
                    'labor_cost_ratio_change_sbl', 'labor_cost_per_employee_sbl', 'labor_to_revenue_sbl',
                    'revenue_per_employee_sbl', 'op_profit_per_employee_sbl', 'hcroi_sbl', 'hcva_sbl',
                    'wage_increase_ce', 'revenue_growth_ce', 'op_profit_growth_ce', 'hcroi_ce', 'hcva_ce',
                    'market_size_growth_rate', 'compensation_competitiveness', 'wage_increase_bu_group',
                    'wage_increase_mi_group', 'wage_increase_total_group', 'public_sector_wage_increase'
                ]
            
            # ë³€ìˆ˜ ë§¤í•‘: Dashboard ë³€ìˆ˜ â†’ ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼
            # ì˜í–¥ìš”ì¸ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜ë“¤ ë§¤í•‘
            variable_mapping = {
                'wage_increase_bu_group': ('wage_increase_bu_group', 0.01),  # 3.0% â†’ 0.03 (ê°€ì¥ ì¤‘ìš”!)
                'gdp_growth': ('gdp_growth_kr', 0.01),      # 2.8% â†’ 0.028
                'unemployment_rate': ('unemployment_rate_kr', 0.01),  # 3.2% â†’ 0.032
                'market_size_growth_rate': ('market_size_growth_rate', 0.01),  # 5.0% â†’ 0.05
                'hcroi_sbl': ('hcroi_sbl', 1.0)  # 1.5ë°° â†’ 1.5 (ë¹„ìœ¨ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ)
            }
            
            # ë°ì´í„°ì—ì„œ ìˆ˜ì¹˜í˜• ê°’ë“¤ì˜ í‰ê· ê°’ ê³„ì‚° (ê²°ì¸¡ê°’ê³¼ '-' ì œì™¸)
            df_clean = None
            if data_service.current_data is not None:
                df_clean = data_service.current_data.copy()
                for col in df_clean.columns:
                    if df_clean[col].dtype == 'object':  # ë¬¸ìì—´ ì»¬ëŸ¼
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
            
            input_data = {}
            
            for col in feature_columns:
                # ë§¤í•‘ëœ ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ê°’ ì ìš©
                mapped_variable = None
                scale_factor = 1.0
                
                for dash_var, (data_col, scale) in variable_mapping.items():
                    if data_col == col and dash_var in variables:
                        mapped_variable = dash_var
                        scale_factor = scale
                        break
                
                if mapped_variable:
                    input_data[col] = variables[mapped_variable] * scale_factor
                else:
                    # í•´ë‹¹ ì»¬ëŸ¼ì˜ í‰ê· ê°’ ì‚¬ìš© (ê²°ì¸¡ê°’ ì œì™¸)
                    if df_clean is not None and col in df_clean.columns:
                        col_mean = df_clean[col].mean()
                        if pd.notna(col_mean):
                            input_data[col] = col_mean
                        else:
                            # ì»¬ëŸ¼ë³„ ê¸°ë³¸ê°’ ì„¤ì •
                            if 'wage' in col or 'increase' in col:
                                input_data[col] = 0.03  # ì„ê¸ˆ ê´€ë ¨ì€ 3%
                            elif 'growth' in col:
                                input_data[col] = 0.02  # ì„±ì¥ë¥  ê´€ë ¨ì€ 2%
                            elif 'rate' in col or 'ratio' in col:
                                input_data[col] = 0.1  # ë¹„ìœ¨ ê´€ë ¨ì€ 10%
                            else:
                                input_data[col] = 0.0
                    else:
                        # ì»¬ëŸ¼ë³„ ê¸°ë³¸ê°’ ì„¤ì •
                        if 'wage' in col or 'increase' in col:
                            input_data[col] = 0.03
                        elif 'growth' in col:
                            input_data[col] = 0.02
                        elif 'rate' in col or 'ratio' in col:
                            input_data[col] = 0.1
                        else:
                            input_data[col] = 0.0
            
            print(f"ğŸ“Š Model input prepared with {len(input_data)} features")
            
            # DataFrame ìƒì„± ì‹œ ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥
            result_df = pd.DataFrame([input_data], columns=feature_columns)
            print(f"âœ… DataFrame shape: {result_df.shape}, columns: {list(result_df.columns)[:5]}...")
            return result_df
                
        except Exception as e:
            logging.error(f"Error preparing model input: {str(e)}")
            print(f"âŒ Error details: {e}")
            
            # í´ë°±: 29ê°œ featureë¡œ ê¸°ë³¸ DataFrame ìƒì„±
            default_features = [
                'gdp_growth_kr', 'cpi_kr', 'unemployment_rate_kr', 'minimum_wage_increase_kr',
                'gdp_growth_usa', 'cpi_usa', 'esi_usa', 'exchange_rate_change_krw',
                'revenue_growth_sbl', 'op_profit_growth_sbl', 'labor_cost_rate_sbl',
                'labor_cost_ratio_change_sbl', 'labor_cost_per_employee_sbl', 'labor_to_revenue_sbl',
                'revenue_per_employee_sbl', 'op_profit_per_employee_sbl', 'hcroi_sbl', 'hcva_sbl',
                'wage_increase_ce', 'revenue_growth_ce', 'op_profit_growth_ce', 'hcroi_ce', 'hcva_ce',
                'market_size_growth_rate', 'compensation_competitiveness', 'wage_increase_bu_group',
                'wage_increase_mi_group', 'wage_increase_total_group', 'public_sector_wage_increase'
            ]
            
            default_data = {}
            for col in default_features:
                if col == 'wage_increase_bu_group':
                    default_data[col] = variables.get('wage_increase_bu_group', 3.0) * 0.01
                elif col == 'gdp_growth_kr':
                    default_data[col] = variables.get('gdp_growth', 2.8) * 0.01
                elif col == 'unemployment_rate_kr':
                    default_data[col] = variables.get('unemployment_rate', 3.2) * 0.01
                elif col == 'market_size_growth_rate':
                    default_data[col] = variables.get('market_size_growth_rate', 5.0) * 0.01
                elif col == 'hcroi_sbl':
                    default_data[col] = variables.get('hcroi_sbl', 1.5)  # ë¹„ìœ¨ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ
                elif col == 'cpi_kr':
                    default_data[col] = 0.025  # ê¸°ë³¸ ì¸í”Œë ˆì´ì…˜ 2.5%
                elif col == 'minimum_wage_increase_kr':
                    default_data[col] = 0.025  # ê¸°ë³¸ ìµœì €ì„ê¸ˆì¸ìƒë¥  2.5%
                else:
                    default_data[col] = 0.02  # ê¸°ë³¸ê°’
            
            return pd.DataFrame([default_data])
    
    def _predict_performance_trend(self) -> float:
        """ê³¼ê±° ì„±ê³¼ ì¸ìƒë¥  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 2026ë…„ ì„±ê³¼ ì¸ìƒë¥  ì˜ˆì¸¡
        
        ë°ì´í„° êµ¬ì¡°:
        - 2021-2024ë…„: ê° ì—°ë„ì˜ ê²½ì œì§€í‘œ + ë‹¤ìŒ í•´ ì„ê¸ˆì¸ìƒë¥ 
        - 2025ë…„: ê²½ì œì§€í‘œë§Œ ìˆìŒ (2026ë…„ ì„ê¸ˆì¸ìƒë¥ ì´ ì˜ˆì¸¡ ëŒ€ìƒ)
        
        ì„±ê³¼ ì¸ìƒë¥  íŠ¸ë Œë“œëŠ” 2022-2025ë…„ ì„ê¸ˆì¸ìƒë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ 2026ë…„ ì˜ˆì¸¡
        """
        try:
            from app.services.data_service import data_service
            from sklearn.linear_model import LinearRegression
            
            if data_service.current_data is None:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì—ëŸ¬
                raise ValueError("No data available for performance trend prediction")
            
            # master_data(ì›ë³¸)ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ current_data ì‚¬ìš©
            if hasattr(data_service, 'master_data') and data_service.master_data is not None:
                df = data_service.master_data.copy()
            else:
                df = data_service.current_data.copy()
            
            # ì„±ê³¼ ì¸ìƒë¥  ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            performance_columns = [
                'wage_increase_mi_sbl',  # SBL Merit Increase (ì„±ê³¼ê¸‰)
                'wage_increase_mi_group',  # ê·¸ë£¹ ì„±ê³¼ê¸‰
                'merit_increase',  # ì„±ê³¼ê¸‰
                'performance_rate',  # ì„±ê³¼ ì¸ìƒë¥ 
            ]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
            available_col = None
            for col in performance_columns:
                if col in df.columns:
                    available_col = col
                    break
            
            if not available_col:
                # ì„±ê³¼ ì¸ìƒë¥  ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, ì´ ì¸ìƒë¥ ì—ì„œ ì¶”ì •
                if 'wage_increase_total_sbl' in df.columns and 'wage_increase_baseup_sbl' in df.columns:
                    # ì´ ì¸ìƒë¥  - Base-up = ì„±ê³¼ ì¸ìƒë¥ 
                    df['estimated_performance'] = df['wage_increase_total_sbl'] - df['wage_increase_baseup_sbl']
                    available_col = 'estimated_performance'
                elif 'wage_increase_total_sbl' in df.columns and 'wage_increase_bu_sbl' in df.columns:
                    df['estimated_performance'] = df['wage_increase_total_sbl'] - df['wage_increase_bu_sbl']
                    available_col = 'estimated_performance'
                elif 'wage_increase_total_group' in df.columns and 'wage_increase_bu_group' in df.columns:
                    df['estimated_performance'] = df['wage_increase_total_group'] - df['wage_increase_bu_group']
                    available_col = 'estimated_performance'
                else:
                    # ì¶”ì •í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì—ëŸ¬
                    raise ValueError("Cannot estimate performance rate from available data")
            
            # ì—°ë„ì™€ ì„±ê³¼ ì¸ìƒë¥  ë°ì´í„° ì¤€ë¹„
            if 'year' in df.columns:
                year_col = 'year'
            elif 'Year' in df.columns:
                year_col = 'Year'
            elif 'eng' in df.columns:
                # eng ì»¬ëŸ¼ì´ ì—°ë„ ë°ì´í„°ì¸ ê²½ìš°
                year_col = 'eng'
            else:
                # ì—°ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì‹¤ì œ ë°ì´í„° ì‹œì‘ ì—°ë„ë¶€í„° ì¸ë±ìŠ¤ ì‚¬ìš©
                df['year'] = range(2021, 2021 + len(df))
                year_col = 'year'
            
            # ë°ì´í„° ì •ë¦¬
            trend_data = df[[year_col, available_col]].copy()
            trend_data.columns = ['year', 'performance_rate']
            
            # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
            trend_data['year'] = pd.to_numeric(trend_data['year'], errors='coerce')
            trend_data['performance_rate'] = pd.to_numeric(trend_data['performance_rate'], errors='coerce')
            trend_data = trend_data.dropna()
            
            # ë°ì´í„°ê°€ í¼ì„¼íŠ¸ë¡œ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (2.0 ì´ìƒì´ë©´ í¼ì„¼íŠ¸ë¡œ ê°„ì£¼)
            if len(trend_data) > 0 and trend_data['performance_rate'].mean() > 0.5:
                print(f"âš ï¸ Data appears to be in percentage format (mean: {trend_data['performance_rate'].mean():.2f})")
                # í¼ì„¼íŠ¸ë¥¼ ë¹„ìœ¨ë¡œ ë³€í™˜ (2.0% -> 0.02)
                trend_data['performance_rate'] = trend_data['performance_rate'] / 100
                print(f"   Converted to ratio format (new mean: {trend_data['performance_rate'].mean():.4f})")
            
            # 2025ë…„ ë°ì´í„° ì œì™¸ (íƒ€ê²Ÿì´ ì—†ëŠ” ì˜ˆì¸¡ ëŒ€ìƒ ë°ì´í„°)
            # ì„±ê³¼ ì¸ìƒë¥ ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©
            trend_data = trend_data[trend_data['performance_rate'].notna()]
            
            # 2025ë…„ ì´í›„ ë°ì´í„° ì œì™¸ (ë¯¸ë˜ ì˜ˆì¸¡ ëŒ€ìƒ)
            trend_data = trend_data[trend_data['year'] < 2025]
            
            if len(trend_data) < 3:
                # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì—ëŸ¬
                raise ValueError("Insufficient data for trend analysis")
            
            # ì‹¤ì œ ë°ì´í„° ê¸°ê°„ ì‚¬ìš© (2021-2025)
            trend_data = trend_data.sort_values('year').tail(10)
            
            # ì„ í˜•íšŒê·€ ëª¨ë¸ í•™ìŠµ
            X = trend_data[['year']].values
            y = trend_data['performance_rate'].values
            
            # ë””ë²„ê¹…: ì‹¤ì œ ë°ì´í„° ê°’ ì¶œë ¥
            print(f"ğŸ“Š Performance rate data for regression:")
            for i, row in trend_data.iterrows():
                print(f"   Year {int(row['year'])}: {row['performance_rate']:.4f} ({row['performance_rate']*100:.2f}%)")
            
            # í‰ê· ê°’ ê³„ì‚° (ë‹¨ìˆœ í‰ê· ë„ ì°¸ê³ )
            mean_performance = y.mean()
            print(f"   Average performance rate: {mean_performance:.4f} ({mean_performance*100:.2f}%)")
            
            lr_model = LinearRegression()
            lr_model.fit(X, y)
            
            # íšŒê·€ ê³„ìˆ˜ ì¶œë ¥
            print(f"   Regression coefficient (slope): {lr_model.coef_[0]:.6f}")
            print(f"   Regression intercept: {lr_model.intercept_:.6f}")
            
            # 2026ë…„ ì˜ˆì¸¡
            prediction_year = np.array([[2026]])
            predicted_performance = lr_model.predict(prediction_year)[0]
            
            print(f"   Raw prediction for 2026: {predicted_performance:.4f} ({predicted_performance*100:.2f}%)")
            
            print(f"ğŸ“Š Final Performance rate prediction for 2026: {predicted_performance:.3f} ({predicted_performance*100:.1f}%)")
            print(f"   Based on {len(trend_data)} years of data from column '{available_col}'")
            
            return float(predicted_performance)
            
        except Exception as e:
            print(f"âš ï¸ Error predicting performance trend: {e}")
            # ì˜¤ë¥˜ ì‹œ ì—ëŸ¬ ë°œìƒ
            raise
    
    def _predict_headcount_2026(self) -> Dict[str, Any]:
        """PyCaretì„ ì‚¬ìš©í•˜ì—¬ 2026ë…„ headcount ì˜ˆì¸¡"""
        try:
            from app.services.data_service import data_service
            from sklearn.linear_model import LinearRegression
            
            if data_service.current_data is None:
                raise ValueError("No data available for headcount prediction")
            
            # master_dataê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ current_data ì‚¬ìš©
            if hasattr(data_service, 'master_data') and data_service.master_data is not None:
                df = data_service.master_data.copy()
            else:
                df = data_service.current_data.copy()
            
            # headcountì™€ year ì»¬ëŸ¼ í™•ì¸
            if 'headcount' not in df.columns:
                raise ValueError("No headcount data available")
            
            # ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸°
            if 'year' in df.columns:
                year_col = 'year'
            elif 'eng' in df.columns:
                year_col = 'eng'
            else:
                # ì—°ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì‹¤ì œ ë°ì´í„° ì‹œì‘ ì—°ë„ë¶€í„° ì¸ë±ìŠ¤ë¡œ ì—°ë„ ìƒì„±
                df['year'] = range(2021, 2021 + len(df))
                year_col = 'year'
            
            # ë°ì´í„° ì •ë¦¬
            headcount_data = df[[year_col, 'headcount']].copy()
            headcount_data.columns = ['year', 'headcount']
            
            # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ ë° ê²°ì¸¡ê°’ ì œê±°
            headcount_data['year'] = pd.to_numeric(headcount_data['year'], errors='coerce')
            headcount_data['headcount'] = pd.to_numeric(headcount_data['headcount'], errors='coerce')
            headcount_data = headcount_data.dropna()
            
            if len(headcount_data) < 2:
                raise ValueError("Insufficient headcount data for prediction")
            
            print(f"ğŸ“Š Headcount data for prediction:")
            for _, row in headcount_data.iterrows():
                print(f"   Year {int(row['year'])}: {int(row['headcount'])} people")
            
            # ì„ í˜•íšŒê·€ ëª¨ë¸ í•™ìŠµ
            X = headcount_data[['year']].values
            y = headcount_data['headcount'].values
            
            lr_model = LinearRegression()
            lr_model.fit(X, y)
            
            # íšŒê·€ ê³„ìˆ˜ ì¶œë ¥
            print(f"   Regression coefficient (slope): {lr_model.coef_[0]:.2f}")
            print(f"   Regression intercept: {lr_model.intercept_:.2f}")
            
            # 2026ë…„ ì˜ˆì¸¡
            prediction_year = np.array([[2026]])
            predicted_headcount = lr_model.predict(prediction_year)[0]
            predicted_headcount = max(0, round(predicted_headcount))  # ìŒìˆ˜ ë°©ì§€ ë° ë°˜ì˜¬ë¦¼
            
            print(f"ğŸ“Š Headcount prediction for 2026: {predicted_headcount} people")
            
            # ì„±ì¥ë¥  ê³„ì‚° (ìµœê·¼ë…„ë„ ëŒ€ë¹„)
            if len(headcount_data) > 0:
                latest_headcount = headcount_data.iloc[-1]['headcount']
                growth_rate = (predicted_headcount - latest_headcount) / latest_headcount
                print(f"   Growth vs latest year: {growth_rate*100:.1f}%")
            else:
                growth_rate = 0
            
            return {
                "predicted_headcount": int(predicted_headcount),
                "growth_rate": float(growth_rate),
                "historical_data": headcount_data.to_dict('records'),
                "model_info": {
                    "slope": float(lr_model.coef_[0]),
                    "intercept": float(lr_model.intercept_),
                    "data_points": len(headcount_data)
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ Error predicting headcount: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "predicted_headcount": 700,  # ê¸°ë³¸ ì˜ˆìƒê°’
                "growth_rate": 0.05,  # 5% ì„±ì¥ ê°€ì •
                "historical_data": [],
                "model_info": {"error": str(e)}
            }

    def predict_wage_increase(self, model, input_data: Dict[str, float], confidence_level: float = 0.95) -> Dict[str, Any]:
        """2026ë…„ ì„ê¸ˆì¸ìƒë¥  ì˜ˆì¸¡
        
        Args:
            model: í•™ìŠµëœ ëª¨ë¸
            input_data: ì˜ˆì¸¡ì— ì‚¬ìš©í•  2025ë…„ ê²½ì œì§€í‘œ ë°ì´í„°
            confidence_level: ì‹ ë¢°êµ¬ê°„ ìˆ˜ì¤€
            
        Returns:
            2026ë…„ ì„ê¸ˆì¸ìƒë¥  ì˜ˆì¸¡ ê²°ê³¼
        """
        
        try:
            # ModelingServiceì—ì„œ 2025ë…„ ë°ì´í„° í™•ì¸
            from app.services.modeling_service import modeling_service
            
            # input_dataê°€ ì—†ê³  modeling_serviceì— 2025ë…„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if not input_data and hasattr(modeling_service, 'prediction_data') and modeling_service.prediction_data is not None:
                # 2025ë…„ ë°ì´í„° ì‚¬ìš©
                print("ğŸ“Š Using 2025 data from modeling service for 2026 prediction")
                model_input = modeling_service.prediction_data.iloc[[0]]  # ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©
                
                # ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ì„ê¸ˆ ê´€ë ¨ ì»¬ëŸ¼ ëª¨ë‘ ì œê±°
                wage_columns_to_remove = [
                    'wage_increase_total_sbl', 'wage_increase_mi_sbl', 'wage_increase_bu_sbl',
                    'wage_increase_baseup_sbl', 'Base-up ì¸ìƒë¥ ', 'ì„±ê³¼ì¸ìƒë¥ ', 'ì„ê¸ˆì¸ìƒë¥ ',
                    'wage_increase_total_group', 'wage_increase_mi_group', 'wage_increase_bu_group'
                ]
                model_input = model_input.drop(columns=wage_columns_to_remove, errors='ignore')
            else:
                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                model_input = self._prepare_model_input(input_data)
            
            # PyCaretì˜ predict_model ì‚¬ìš©
            try:
                from pycaret.regression import predict_model
                predictions_df = predict_model(model, data=model_input)
                # 'prediction_label' ì»¬ëŸ¼ì—ì„œ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
                if 'prediction_label' in predictions_df.columns:
                    prediction = predictions_df['prediction_label'].iloc[0]
                elif 'Label' in predictions_df.columns:
                    prediction = predictions_df['Label'].iloc[0]
                else:
                    # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì´ ì˜ˆì¸¡ê°’ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                    prediction = predictions_df.iloc[0, -1]
            except Exception as e:
                logging.warning(f"PyCaret predict_model failed, using direct prediction: {e}")
                # í´ë°±: ì§ì ‘ ì˜ˆì¸¡ ì‹œë„
                prediction = model.predict(model_input)[0]
            
            # ì„±ê³¼ ì¸ìƒë¥ ì€ ì ì •ì¸ë ¥ ì‚°ì •ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            performance_rate = 0.0
            
            # 2026ë…„ headcount ì˜ˆì¸¡ ì¶”ê°€
            headcount_prediction = self._predict_headcount_2026()
            
            # ë°˜ì˜¬ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ë§Œ ìœ ì§€
            raw_prediction = round(float(prediction), 4)
            performance_rate = round(performance_rate, 4)
            
            # ìµœê·¼ íŠ¸ë Œë“œ ë°˜ì˜í•œ ì¡°ì •
            # ìµœê·¼ 2ë…„ì´ 5.3%, 5.6%ë¡œ ë†’ì€ ì¸ìƒë¥ ì„ ë³´ì„
            from app.services.data_service import data_service
            
            # ê·¸ë£¹ Base-upì˜ ë…¼ë¦¬ì  ì˜í–¥ ë°˜ì˜
            # ê·¸ë£¹ Base-upì´ ë†’ìœ¼ë©´ SBL ì„ê¸ˆë„ ë†’ì•„ì•¼ í•¨ (ìƒì‹ì  ê´€ê³„)
            if isinstance(input_data, dict) and 'wage_increase_bu_group' in input_data:
                group_baseup_input = input_data['wage_increase_bu_group']
                # ê¸°ì¤€ê°’(3.0%)ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
                baseup_diff = (group_baseup_input - 3.0) * 0.01
                # ì–‘ì˜ ê´€ê³„ë¡œ ì¡°ì • (ê·¸ë£¹ base-up 1%p ì¦ê°€ â†’ ì˜ˆì¸¡ê°’ 0.3%p ì¦ê°€)
                logical_adjustment = baseup_diff * 0.3
                prediction_value = round(raw_prediction + logical_adjustment, 4)
            else:
                prediction_value = raw_prediction
            
            print(f"ğŸ” Debug - Raw model prediction: {raw_prediction:.4f} ({raw_prediction*100:.2f}%)")
            print(f"ğŸ” Debug - Adjusted prediction (60% model + 40% trend): {prediction_value:.4f} ({prediction_value*100:.2f}%)")
            print(f"ğŸ” Debug - Performance rate (from trend): {performance_rate:.4f} ({performance_rate*100:.2f}%)")
            
            # Base-up = ì´ ì¸ìƒë¥  - ì„±ê³¼ ì¸ìƒë¥ 
            base_up_rate = round(prediction_value - performance_rate, 4)
            print(f"ğŸ” Debug - Base-up (total - performance): {base_up_rate:.4f} ({base_up_rate*100:.2f}%)")
            
            # Base-upì´ ìŒìˆ˜ì¸ ê²½ìš° - ì„±ê³¼ ì¸ìƒë¥ ì€ ë³€ê²½í•˜ì§€ ì•Šê³  base_upë§Œ ì¡°ì •
            if base_up_rate < 0:
                print(f"âš ï¸ Debug - Base-up negative ({base_up_rate:.4f}), setting to 0")
                base_up_rate = 0
                # ì„±ê³¼ ì¸ìƒë¥ ì€ íŠ¸ë Œë“œ ì˜ˆì¸¡ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€
            
            # ì„±ê³¼ ì¸ìƒë¥ ì´ ì´ ì˜ˆì¸¡ê°’ë³´ë‹¤ í° ê²½ìš° - ì„±ê³¼ ì¸ìƒë¥ ì€ ìœ ì§€í•˜ê³  base_upì„ 0ìœ¼ë¡œ
            if performance_rate > prediction_value:
                print(f"âš ï¸ Debug - Performance ({performance_rate:.4f}) > Total ({prediction_value:.4f})")
                print(f"âš ï¸ Debug - Keeping performance rate as is, setting base_up to 0")
                base_up_rate = 0
                # ì„±ê³¼ ì¸ìƒë¥ ì€ íŠ¸ë Œë“œ ì˜ˆì¸¡ê°’ ê·¸ëŒ€ë¡œ ìœ ì§€
            
            # ìµœì¢… ê²€ì¦: í•©ê³„ê°€ ì´ ì˜ˆì¸¡ê°’ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì¡°ì •
            calculated_total = round(base_up_rate + performance_rate, 4)
            if abs(calculated_total - prediction_value) > 0.0001:
                # ì°¨ì´ê°€ ìˆìœ¼ë©´ base_up_rateë¡œ ì¡°ì •
                base_up_rate = round(prediction_value - performance_rate, 4)
            
            print(f"âœ… Debug - FINAL VALUES:")
            print(f"   Performance: {performance_rate:.4f} ({performance_rate*100:.2f}%)")
            print(f"   Base-up: {base_up_rate:.4f} ({base_up_rate*100:.2f}%)")
            print(f"   Total: {prediction_value:.4f} ({prediction_value*100:.2f}%)")
            print(f"   Sum check: {base_up_rate + performance_rate:.4f} vs {prediction_value:.4f}")
            
            # ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²• - ì”ì°¨ ê¸°ë°˜)
            try:
                from pycaret.regression import get_config
                X_train = get_config('X_train')
                y_train = get_config('y_train')
                
                if X_train is not None and y_train is not None:
                    train_predictions = model.predict(X_train)
                    residuals = y_train - train_predictions
                    residual_std = np.std(residuals)
                    
                    # ì‹ ë¢°êµ¬ê°„
                    from scipy import stats
                    alpha = 1 - confidence_level
                    z_score = stats.norm.ppf(1 - alpha/2)
                    margin_error = z_score * residual_std
                    
                    confidence_interval = [
                        float(prediction - margin_error),
                        float(prediction + margin_error)
                    ]
                else:
                    # PyCaret configê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
                    confidence_interval = [
                        round(prediction_value * 0.95, 4),
                        round(prediction_value * 1.05, 4)
                    ]
            except:
                confidence_interval = [
                    round(prediction_value * 0.95, 4),
                    round(prediction_value * 1.05, 4)
                ]
            
            return {
                "message": "Wage increase prediction completed",
                "prediction": prediction_value,
                "base_up_rate": base_up_rate,
                "performance_rate": performance_rate,
                "confidence_interval": confidence_interval,
                "confidence_level": confidence_level,
                "input_variables": input_data,
                "prediction_date": datetime.now().strftime("%Y-%m-%d"),
                "model_type": type(model).__name__,
                "headcount_prediction": headcount_prediction,  # 2026ë…„ headcount ì˜ˆì¸¡ ì¶”ê°€
                "breakdown": {
                    "base_up": {
                        "rate": base_up_rate,
                        "percentage": round(base_up_rate * 100, 2),
                        "description": "ê¸°ë³¸ ì¸ìƒë¶„",
                        "calculation": "ì´ ì¸ìƒë¥  - ì„±ê³¼ ì¸ìƒë¥ "
                    },
                    "performance": {
                        "rate": performance_rate,
                        "percentage": round(performance_rate * 100, 2),
                        "description": "ê³¼ê±° 10ë…„ ì„±ê³¼ê¸‰ ì¶”ì„¸ ê¸°ë°˜ ì˜ˆì¸¡",
                        "calculation": "ì„ í˜•íšŒê·€ ë¶„ì„ìœ¼ë¡œ ì˜ˆì¸¡"
                    },
                    "total": {
                        "rate": prediction_value,
                        "percentage": round(prediction_value * 100, 2),
                        "description": "2026ë…„ ì´ ì„ê¸ˆ ì¸ìƒë¥  ì˜ˆì¸¡",
                        "verification": f"{round(base_up_rate * 100, 2)}% + {round(performance_rate * 100, 2)}% = {round(prediction_value * 100, 2)}%"
                    }
                }
            }
            
        except Exception as e:
            logging.error(f"Prediction failed: {str(e)}")
            raise Exception(f"Prediction failed: {str(e)}")
    
    def get_scenario_templates(self) -> List[Dict[str, Any]]:
        """ì‹œë‚˜ë¦¬ì˜¤ í…œí”Œë¦¿ ëª©ë¡ ë°˜í™˜"""
        
        templates = []
        for key, template in self.scenario_templates.items():
            templates.append({
                "id": key,
                "name": template["name"],
                "description": template["description"],
                "variables": template["variables"]
            })
        
        return templates
    
    def get_available_variables(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜ ëª©ë¡ê³¼ ì •ì˜ ë°˜í™˜"""
        
        variables = []
        current_values = {}
        
        for key, definition in self.variable_definitions.items():
            variables.append({
                "name": key,
                "display_name": definition["name"],
                "description": definition["description"],
                "min_value": definition["min_value"],
                "max_value": definition["max_value"],
                "unit": definition["unit"],
                "current_value": definition["current_value"]
            })
            current_values[key] = definition["current_value"]
        
        return {
            "variables": variables,
            "current_values": current_values
        }
    
    def get_economic_indicators(self) -> Dict[str, Any]:
        """ì£¼ìš” ê²½ì œ ì§€í‘œ ë°˜í™˜"""
        
        # ì‹¤ì œ ë°ì´í„°ë‚˜ ì™¸ë¶€ APIì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í™•ì¥ ê°€ëŠ¥
        return {
            "indicators": {
                "current_inflation": 2.5,
                "current_gdp_growth": 2.8,
                "current_unemployment": 3.2,
                "current_wage_growth": 3.5,
                "last_year_wage_growth": 3.8,
                "industry_average": 3.2,
                "public_sector_average": 2.9
            },
            "last_updated": datetime.now().strftime("%Y-%m-%d")
        }
    
    def perform_scenario_analysis(self, model, scenarios: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰"""
        
        results = []
        
        for scenario in scenarios:
            try:
                prediction_result = self.predict_wage_increase(
                    model,
                    scenario["variables"]
                )
                
                results.append({
                    "scenario_name": scenario.get("scenario_name", "Custom"),
                    "prediction": prediction_result["prediction"],
                    "confidence_interval": prediction_result["confidence_interval"],
                    "variables": scenario["variables"]
                })
                
            except Exception as e:
                logging.error(f"Scenario analysis failed for {scenario.get('scenario_name')}: {str(e)}")
                results.append({
                    "scenario_name": scenario.get("scenario_name", "Custom"),
                    "error": str(e)
                })
        
        return results
    
    def perform_sensitivity_analysis(self, model, base_variables: Dict[str, float], 
                                    target_variable: str, value_range: List[float]) -> Dict[str, Any]:
        """ë¯¼ê°ë„ ë¶„ì„ ìˆ˜í–‰"""
        
        results = []
        
        for value in value_range:
            test_variables = base_variables.copy()
            test_variables[target_variable] = value
            
            try:
                prediction_result = self.predict_wage_increase(model, test_variables)
                results.append({
                    "variable_value": value,
                    "prediction": prediction_result["prediction"]
                })
            except Exception as e:
                logging.error(f"Sensitivity analysis failed for {target_variable}={value}: {str(e)}")
                results.append({
                    "variable_value": value,
                    "error": str(e)
                })
        
        return {
            "target_variable": target_variable,
            "base_value": base_variables.get(target_variable),
            "results": results
        }
    
    def get_trend_data(self) -> Dict[str, Any]:
        """íŠ¸ë Œë“œ ë°ì´í„° ë°˜í™˜"""
        
        try:
            # ì›ë³¸ master_data íŒŒì¼ ë¡œë“œ
            import pickle
            import os
            
            master_data_path = os.path.join(os.path.dirname(__file__), '../../data/master_data.pkl')
            
            if os.path.exists(master_data_path):
                with open(master_data_path, 'rb') as f:
                    data = pickle.load(f)
                    # dataê°€ dictì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
                    if isinstance(data, dict):
                        if 'data' in data:
                            df = data['data']
                        else:
                            df = pd.DataFrame(data)
                    else:
                        df = data
                print(f"âœ… Loaded original master_data from {master_data_path}")
            elif data_service.current_data is not None:
                df = data_service.current_data.copy()
                print("âš ï¸ Using current_data (may contain augmented data)")
            else:
                df = None
            
            if df is not None:
                # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸° (headcount ë°ì´í„°)
                target_col = 'headcount'
                if target_col not in df.columns:
                    # ë‹¤ë¥¸ ê°€ëŠ¥í•œ headcount ì»¬ëŸ¼ë“¤ ì‹œë„
                    for col in ['ì •ì›', 'employee_count', 'total_headcount']:
                        if col in df.columns:
                            target_col = col
                            break
                
                # year ë˜ëŠ” eng ì»¬ëŸ¼ ì°¾ê¸°
                year_col = 'year' if 'year' in df.columns else 'eng' if 'eng' in df.columns else None
                
                if target_col in df.columns and year_col:
                    # ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš© (master_dataëŠ” ì´ë¯¸ ì›ë³¸)
                    yearly_data = df.groupby(year_col)[target_col].first().dropna()
                    
                    # ê³¼ê±° ë°ì´í„° í¬ë§·íŒ…
                    # Headcount ì—°ë„ë³„ ë°ì´í„°
                    historical_data = []
                    
                    for year, value in yearly_data.items():
                        if pd.notna(value):
                            # headcountëŠ” ì ˆëŒ€ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            display_value = int(float(value))
                            actual_year = int(year)
                            
                            data_point = {
                                "year": actual_year,
                                "value": display_value,
                                "type": "historical"
                            }
                            
                            historical_data.append(data_point)
                    
                    # 2026ë…„ ì˜ˆì¸¡ ë°ì´í„° ì¶”ê°€ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
                    # ì´ë¯¸ 2026ë…„ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    has_2026 = any(d.get('year') == 2026 for d in historical_data)
                    
                    from app.services.modeling_service import modeling_service
                    if modeling_service.current_model and not has_2026:
                        try:
                            # ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
                            default_input = {
                                'wage_increase_bu_group': 3.0,
                                'gdp_growth': 2.8,
                                'unemployment_rate': 3.2,
                                'market_size_growth_rate': 5.0,
                                'hcroi_sbl': 1.5
                            }
                            
                            # ì˜ˆì¸¡ ìˆ˜í–‰
                            prediction_result = self.predict_wage_increase(
                                modeling_service.current_model,
                                default_input,
                                confidence_level=0.95
                            )
                            
                            # ì˜ˆì¸¡ê°’ ê²€ì¦
                            pred_value = prediction_result["prediction"]
                            base_up = prediction_result.get("base_up_rate", 0)
                            perf = prediction_result.get("performance_rate", 0)
                            
                            # ë¹„ì •ìƒì ì¸ ê°’ ì²´í¬ (ì˜ˆ: 100% ì´ìƒ ë˜ëŠ” ìŒìˆ˜)
                            if abs(pred_value) > 1.0 or pred_value < 0:
                                print(f"âš ï¸ Abnormal prediction value: {pred_value}")
                                raise ValueError("Abnormal prediction value")
                            
                            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
                            prediction_data = {
                                "year": 2026,
                                "value": round(pred_value * 100, 2),
                                "base_up": round(base_up * 100, 2),
                                "performance": round(perf * 100, 2),
                                "type": "prediction"
                            }
                            historical_data.append(prediction_data)
                            
                            # Base-up ë°ì´í„°ë„ ë³„ë„ë¡œ ì¶”ê°€ (ì°¨íŠ¸ì—ì„œ ì‚¬ìš©)
                            if hasbaseup and 'baseup_data' in locals():
                                baseup_pred = {
                                    "year": 2026,
                                    "value": round(prediction_result.get("base_up_rate", 0) * 100, 2),
                                    "type": "prediction"
                                }
                                baseup_data.append(baseup_pred)
                            
                            print(f"âœ… Added 2026 prediction: Total={prediction_data['value']}%, Base-up={prediction_data['base_up']}%")
                        except Exception as e:
                            print(f"âš ï¸ Could not generate prediction: {e}")
                            # ì˜¤ë¥˜ ì‹œì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ ë°©ì§€)
                            pass
                    
                    return {
                        "message": "Trend data retrieved successfully",
                        "trend_data": historical_data,
                        "baseup_data": baseup_data if 'baseup_data' in locals() else [],
                        "chart_config": {
                            "title": "ì¸ì› ìˆ˜ ì¶”ì´ ë° 2026ë…„ ì˜ˆì¸¡",
                            "y_axis_label": "ì¸ì› ìˆ˜ (ëª…)",
                            "x_axis_label": "ì—°ë„"
                        }
                    }
            
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
            return {
                "message": "No trend data available",
                "trend_data": [],
                "chart_config": {
                    "title": "ì¸ì› ìˆ˜ ì¶”ì´",
                    "y_axis_label": "ì¸ì› ìˆ˜ (ëª…)",
                    "x_axis_label": "ì—°ë„"
                }
            }
            
        except Exception as e:
            logging.error(f"Failed to get trend data: {str(e)}")
            return {
                "message": f"Error: {str(e)}",
                "trend_data": [],
                "chart_config": {}
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
dashboard_service = DashboardService()
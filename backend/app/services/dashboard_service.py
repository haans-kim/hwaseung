import logging
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from app.services.data_service import data_service

class DashboardService:
    def __init__(self):
        self.scenario_templates = {
            "base": {
                "name": "ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤",
                "description": "í˜„ì¬ ê²½ì œ ìƒí™© ê¸°ì¤€",
                "variables": {
                    "oil_gl": -13.7,
                    "exchange_rate_change_krw": 4.2,
                    "vp_export_kr": -0.14,
                    "cpi_kr": 1.8,
                    "v_export_kr": 20.0
                }
            },
            "optimistic": {
                "name": "ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ê³ ìœ ê°€ + ìˆ˜ì¶œ ì¦ê°€",
                "variables": {
                    "oil_gl": 30.0,
                    "exchange_rate_change_krw": 10.0,
                    "vp_export_kr": 20.0,
                    "cpi_kr": 5.0,
                    "v_export_kr": 25.0
                }
            },
            "moderate": {
                "name": "ì¤‘ë¦½ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ì•ˆì •ì  ê²½ì œ ì„±ì¥",
                "variables": {
                    "oil_gl": 0.0,
                    "exchange_rate_change_krw": 2.0,
                    "vp_export_kr": 5.0,
                    "cpi_kr": 3.0,
                    "v_export_kr": 10.0
                }
            },
            "pessimistic": {
                "name": "ë¹„ê´€ì  ì‹œë‚˜ë¦¬ì˜¤",
                "description": "ì €ìœ ê°€ + ìˆ˜ì¶œ ê°ì†Œ",
                "variables": {
                    "oil_gl": -30.0,
                    "exchange_rate_change_krw": -10.0,
                    "vp_export_kr": -20.0,
                    "cpi_kr": 0.5,
                    "v_export_kr": -15.0
                }
            }
        }
        
        # Feature importanceê¸°ë°˜ ìƒìœ„ ë³€ìˆ˜ë“¤ ë™ì  ì„ ì •
        self.variable_definitions = self._build_variable_definitions()
    
    def _build_variable_definitions(self) -> Dict[str, Dict[str, Any]]:
        """ê¸°ë°˜ Importanceì™€ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë³€ìˆ˜ ì •ì˜ ë™ì  ìƒì„±"""
        try:
            # 1. Feature importance ê°€ì ¸ì˜¤ê¸°
            top_features = self._get_top_features()
            
            # 2. 2025ë…„ ì‹¤ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            actual_values = self._get_2025_actual_data()
            
            # 3. ë³€ìˆ˜ ì •ì˜ ìƒì„±
            variable_defs = {}
            
            # ë³€ìˆ˜ë³„ ë©”íƒ€ ì •ë³´ ë§¤í•‘
            feature_meta = {
                'oil_gl': {
                    'name': 'ê¸€ë¡œë²Œ ìœ ê°€',
                    'description': 'êµ­ì œ ìœ ê°€ ë³€ë™ë¥  (%)',
                    'min_value': -50.0, 'max_value': 50.0, 'unit': '%'
                },
                'exchange_rate_change_krw': {
                    'name': 'í™˜ìœ¨ ë³€ë™ë¥ ',
                    'description': 'ì›ë‹¬ëŸ¬ í™˜ìœ¨ ë³€ë™ë¥  (%)',
                    'min_value': -15.0, 'max_value': 20.0, 'unit': '%'
                },
                'vp_export_kr': {
                    'name': 'ìˆ˜ì¶œ ë³€ë™ë¥ ',
                    'description': 'í•œêµ­ ìˆ˜ì¶œ ë³€ë™ë¥  (%)',
                    'min_value': -30.0, 'max_value': 30.0, 'unit': '%'
                },
                'cpi_kr': {
                    'name': 'ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜',
                    'description': 'í•œêµ­ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ ì¦ê°€ìœ¨ (%)',
                    'min_value': -2.0, 'max_value': 8.0, 'unit': '%'
                },
                'v_export_kr': {
                    'name': 'ìˆ˜ì¶œì•¡',
                    'description': 'í•œêµ­ ìˆ˜ì¶œì•¡ ì¦ê°€ìœ¨ (%)',
                    'min_value': -25.0, 'max_value': 25.0, 'unit': '%'
                },
                'v_growth_gl': {
                    'name': 'ê¸€ë¡œë²Œ ë§¤ì¶œ ì„±ì¥',
                    'description': 'ê¸€ë¡œë²Œ ë§¤ì¶œ ì„±ì¥ë¥  (%)',
                    'min_value': -20.0, 'max_value': 30.0, 'unit': '%'
                },
                'ev_growth_gl': {
                    'name': 'ê¸€ë¡œë²Œ ê¸°ì—…ê°€ì¹˜',
                    'description': 'ê¸€ë¡œë²Œ ê¸°ì—…ê°€ì¹˜ ì„±ì¥ë¥  (%)',
                    'min_value': -15.0, 'max_value': 25.0, 'unit': '%'
                },
                'gdp_growth_kr': {
                    'name': 'GDP ì„±ì¥ë¥ ',
                    'description': 'í•œêµ­ GDP ì„±ì¥ë¥  (%)',
                    'min_value': -5.0, 'max_value': 8.0, 'unit': '%'
                },
                'scm_index_gl': {
                    'name': 'ê³µê¸‰ë§ ì§€ìˆ˜',
                    'description': 'ê¸€ë¡œë²Œ ê³µê¸‰ë§ ì§€ìˆ˜',
                    'min_value': 500, 'max_value': 2000, 'unit': ''
                },
                'production_capa': {
                    'name': 'ìƒì‚° ëŠ¥ë ¥',
                    'description': 'ìƒì‚° ëŠ¥ë ¥ ì§€ìˆ˜',
                    'min_value': 0.5, 'max_value': 2.0, 'unit': ''
                },
                'operating_income': {
                    'name': 'ì˜ì—…ì´ìµ ì¦ê°€ìœ¨',
                    'description': 'ì˜ì—…ì´ìµ ì¦ê°€ìœ¨ (%)',
                    'min_value': -30.0, 'max_value': 50.0, 'unit': '%'
                }
            }
            
            # ìƒìœ„ featureë“¤ì— ëŒ€í•´ ë³€ìˆ˜ ì •ì˜ ìƒì„±
            for feature in top_features:
                if feature in feature_meta and feature in actual_values:
                    meta = feature_meta[feature]
                    variable_defs[feature] = {
                        'name': meta['name'],
                        'description': meta['description'],
                        'min_value': meta['min_value'],
                        'max_value': meta['max_value'],
                        'unit': meta['unit'],
                        'current_value': actual_values[feature]  # ì‹¤ì œ 2025ë…„ ë°ì´í„°
                    }
            
            print(f"âœ… Built {len(variable_defs)} variable definitions from top features: {list(variable_defs.keys())}")
            return variable_defs
            
        except Exception as e:
            print(f"âš ï¸ Failed to build variable definitions: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ - í•˜ë“œì½”ë”© ê¸ˆì§€
            return {}
    
    def _get_top_features(self) -> List[str]:
        """í˜„ì¬ ëª¨ë¸ì—ì„œ SHAP Feature importance ê¸°ë°˜ ìƒìœ„ 5ê°œ ë³€ìˆ˜ ë°˜í™˜"""
        try:
            from app.services.analysis_service import analysis_service
            from app.services.modeling_service import modeling_service
            
            # ëª¨ë¸ í™•ì¸
            if modeling_service.current_model is None:
                raise ValueError("No model loaded")
            
            # SHAP Feature Importance ê°€ì ¸ì˜¤ê¸° (ì°¨íŠ¸ì™€ ë™ì¼í•œ ì†ŒìŠ¤)
            feature_importance_result = analysis_service.get_feature_importance(
                model=modeling_service.current_model,
                method='shap',
                top_n=10
            )
            
            if 'feature_importance' not in feature_importance_result:
                raise ValueError("Failed to get feature importance")
            
            # ìƒìœ„ 5ê°œ feature ì¶”ì¶œ
            top_5_features = [
                item['feature'] 
                for item in feature_importance_result['feature_importance'][:5]
            ]
            
            print(f"âœ… Top 5 features by SHAP importance: {top_5_features}")
            return top_5_features
            
        except Exception as e:
            print(f"âš ï¸ Failed to calculate SHAP feature importance: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜í•˜ì—¬ ë³€ìˆ˜ ì •ì˜ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ
            return []
    
    def _get_2025_actual_data(self) -> Dict[str, float]:
        """ì‹¤ì œ 2025ë…„ ë°ì´í„°ì—ì„œ ê°’ë“¤ ì¶”ì¶œ"""
        try:
            from app.services.data_service import data_service
            
            if data_service.current_data is None:
                raise ValueError("No data available")
                
            df = data_service.current_data
            year_2025_data = df[df['eng'] == 2025]
            
            if len(year_2025_data) == 0:
                raise ValueError("No 2025 data found")
            
            row = year_2025_data.iloc[0]
            result = {}
            
            # ëª¨ë“  feature ì»´ëŸ¼ì— ëŒ€í•´ ê°’ ì¶”ì¶œ
            for col in df.columns:
                if col not in ['headcount', 'eng']:
                    value = pd.to_numeric(row[col], errors='coerce')
                    if pd.notna(value):
                        result[col] = float(value)
                    else:
                        result[col] = 0.0
            
            print(f"âœ… Extracted 2025 actual data for {len(result)} features")
            return result
            
        except Exception as e:
            print(f"âš ï¸ Failed to get 2025 actual data: {e}")
            return {}
    
    def _prepare_model_input(self, variables: Dict[str, float]) -> pd.DataFrame:
        """ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ëŠ” ëª¨ë¸ ì…ë ¥ ì¤€ë¹„"""
        try:
            from app.services.data_service import data_service
            
            # ì‹¤ì œ ë°ì´í„°ì˜ ì»¬ëŸ¼ êµ¬ì¡° ì‚¬ìš© (headcount ì œì™¸)
            if data_service.current_data is None:
                raise ValueError("No data available")
                
            all_columns = list(data_service.current_data.columns)
            feature_columns = [col for col in all_columns if col not in ['headcount', 'eng']]
            
            print(f"âœ… Using actual data columns: {feature_columns}")
            
            # ì‹¤ì œ ë°ì´í„°ì—ì„œ ìµœì‹ ê°’ ê°€ì ¸ì˜¤ê¸°
            df = data_service.current_data.copy()
            latest_row = df.iloc[-1]  # ìµœì‹  ë°ì´í„° (2024ë…„)
            
            input_data = {}
            
            for col in feature_columns:
                if col in variables:
                    # ì‚¬ìš©ìê°€ ì¡°ì •í•œ ë³€ìˆ˜ ì‚¬ìš©
                    input_data[col] = variables[col]
                    print(f"  âœ… Using user input for {col}: {variables[col]}")
                else:
                    # ìµœì‹  ë°ì´í„°ê°’ ì‚¬ìš©
                    value = pd.to_numeric(latest_row[col], errors='coerce')
                    if pd.notna(value):
                        input_data[col] = value
                    else:
                        # ê¸°ë³¸ê°’
                        input_data[col] = 0.0
            
            result_df = pd.DataFrame([input_data], columns=feature_columns)
            print(f"âœ… Model input shape: {result_df.shape}")
            print(f"   Adjustable variables: {[k for k in variables.keys() if k in feature_columns]}")
            return result_df
            
        except Exception as e:
            print(f"âŒ Error in _prepare_model_input: {e}")
            raise e
    
    def _predict_performance_trend(self) -> float:
        """ê³¼ê±° ì„±ê³¼ ì¸ìƒë¥  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 2026ë…„ ì„±ê³¼ ì¸ìƒë¥  ì˜ˆì¸¡
        
        ë°ì´í„° êµ¬ì¡°:
        - 2021-2024ë…„: ê° ì—°ë„ì˜ ê²½ì œì§€í‘œ + ë‹¤ìŒ í•´ ì„ê¸ˆì¸ìƒë¥ 
        - 2025ë…„: ê²½ì œì§€í‘œë§Œ ìˆìŒ (2026ë…„ ì„ê¸ˆì¸ìƒë¥ ì´ ì˜ˆì¸¡ ëŒ€ìƒ)
        
        ì„±ê³¼ ì¸ìƒë¥  íŠ¸ë Œë“œëŠ” 2022-2025ë…„ ì„ê¸ˆì¸ìƒë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ 2026ë…„ ì˜ˆì¸¡
        """
        try:
            from app.services.data_service import data_service
            from sklearn.linear_model import LinearRegression
            
            if data_service.current_data is None:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ì—ëŸ¬
                raise ValueError("No data available for performance trend prediction")
            
            # master_data(ì›ë³¸)ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ current_data ì‚¬ìš©
            if hasattr(data_service, 'master_data') and data_service.master_data is not None:
                df = data_service.master_data.copy()
            else:
                df = data_service.current_data.copy()
            
            # ì„±ê³¼ ì¸ìƒë¥  ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            performance_columns = [
                'wage_increase_mi_sbl',  # SBL Merit Increase (ì„±ê³¼ê¸‰)
                'wage_increase_mi_group',  # ê·¸ë£¹ ì„±ê³¼ê¸‰
                'merit_increase',  # ì„±ê³¼ê¸‰
                'performance_rate',  # ì„±ê³¼ ì¸ìƒë¥ 
            ]
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
            available_col = None
            for col in performance_columns:
                if col in df.columns:
                    available_col = col
                    break
            
            if not available_col:
                # ì„±ê³¼ ì¸ìƒë¥  ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, ì´ ì¸ìƒë¥ ì—ì„œ ì¶”ì •
                if 'wage_increase_total_sbl' in df.columns and 'wage_increase_baseup_sbl' in df.columns:
                    # ì´ ì¸ìƒë¥  - Base-up = ì„±ê³¼ ì¸ìƒë¥ 
                    df['estimated_performance'] = df['wage_increase_total_sbl'] - df['wage_increase_baseup_sbl']
                    available_col = 'estimated_performance'
                elif 'wage_increase_total_sbl' in df.columns and 'wage_increase_bu_sbl' in df.columns:
                    df['estimated_performance'] = df['wage_increase_total_sbl'] - df['wage_increase_bu_sbl']
                    available_col = 'estimated_performance'
                elif 'wage_increase_total_group' in df.columns and 'wage_increase_bu_group' in df.columns:
                    df['estimated_performance'] = df['wage_increase_total_group'] - df['wage_increase_bu_group']
                    available_col = 'estimated_performance'
                else:
                    # ì¶”ì •í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì—ëŸ¬
                    raise ValueError("Cannot estimate performance rate from available data")
            
            # ì—°ë„ì™€ ì„±ê³¼ ì¸ìƒë¥  ë°ì´í„° ì¤€ë¹„
            if 'year' in df.columns:
                year_col = 'year'
            elif 'Year' in df.columns:
                year_col = 'Year'
            elif 'eng' in df.columns:
                # eng ì»¬ëŸ¼ì´ ì—°ë„ ë°ì´í„°ì¸ ê²½ìš°
                year_col = 'eng'
            else:
                # ì—°ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì‹¤ì œ ë°ì´í„° ì‹œì‘ ì—°ë„ë¶€í„° ì¸ë±ìŠ¤ ì‚¬ìš©
                df['year'] = range(2021, 2021 + len(df))
                year_col = 'year'
            
            # ë°ì´í„° ì •ë¦¬
            trend_data = df[[year_col, available_col]].copy()
            trend_data.columns = ['year', 'performance_rate']
            
            # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
            trend_data['year'] = pd.to_numeric(trend_data['year'], errors='coerce')
            trend_data['performance_rate'] = pd.to_numeric(trend_data['performance_rate'], errors='coerce')
            trend_data = trend_data.dropna()
            
            # ë°ì´í„°ê°€ í¼ì„¼íŠ¸ë¡œ ì €ì¥ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (2.0 ì´ìƒì´ë©´ í¼ì„¼íŠ¸ë¡œ ê°„ì£¼)
            if len(trend_data) > 0 and trend_data['performance_rate'].mean() > 0.5:
                print(f"âš ï¸ Data appears to be in percentage format (mean: {trend_data['performance_rate'].mean():.2f})")
                # í¼ì„¼íŠ¸ë¥¼ ë¹„ìœ¨ë¡œ ë³€í™˜ (2.0% -> 0.02)
                trend_data['performance_rate'] = trend_data['performance_rate'] / 100
                print(f"   Converted to ratio format (new mean: {trend_data['performance_rate'].mean():.4f})")
            
            # 2025ë…„ ë°ì´í„° ì œì™¸ (íƒ€ê²Ÿì´ ì—†ëŠ” ì˜ˆì¸¡ ëŒ€ìƒ ë°ì´í„°)
            # ì„±ê³¼ ì¸ìƒë¥ ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©
            trend_data = trend_data[trend_data['performance_rate'].notna()]
            
            # 2025ë…„ ì´í›„ ë°ì´í„° ì œì™¸ (ë¯¸ë˜ ì˜ˆì¸¡ ëŒ€ìƒ)
            trend_data = trend_data[trend_data['year'] < 2025]
            
            if len(trend_data) < 3:
                # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì—ëŸ¬
                raise ValueError("Insufficient data for trend analysis")
            
            # ì‹¤ì œ ë°ì´í„° ê¸°ê°„ ì‚¬ìš© (2021-2025)
            trend_data = trend_data.sort_values('year').tail(10)
            
            # ì„ í˜•íšŒê·€ ëª¨ë¸ í•™ìŠµ
            X = trend_data[['year']].values
            y = trend_data['performance_rate'].values
            
            # ë””ë²„ê¹…: ì‹¤ì œ ë°ì´í„° ê°’ ì¶œë ¥
            print(f"ğŸ“Š Performance rate data for regression:")
            for i, row in trend_data.iterrows():
                print(f"   Year {int(row['year'])}: {row['performance_rate']:.4f} ({row['performance_rate']*100:.2f}%)")
            
            # í‰ê· ê°’ ê³„ì‚° (ë‹¨ìˆœ í‰ê· ë„ ì°¸ê³ )
            mean_performance = y.mean()
            print(f"   Average performance rate: {mean_performance:.4f} ({mean_performance*100:.2f}%)")
            
            lr_model = LinearRegression()
            lr_model.fit(X, y)
            
            # íšŒê·€ ê³„ìˆ˜ ì¶œë ¥
            print(f"   Regression coefficient (slope): {lr_model.coef_[0]:.6f}")
            print(f"   Regression intercept: {lr_model.intercept_:.6f}")
            
            # 2026ë…„ ì˜ˆì¸¡
            prediction_year = np.array([[2026]])
            predicted_performance = lr_model.predict(prediction_year)[0]
            
            print(f"   Raw prediction for 2026: {predicted_performance:.4f} ({predicted_performance*100:.2f}%)")
            
            print(f"ğŸ“Š Final Performance rate prediction for 2026: {predicted_performance:.3f} ({predicted_performance*100:.1f}%)")
            print(f"   Based on {len(trend_data)} years of data from column '{available_col}'")
            
            return float(predicted_performance)
            
        except Exception as e:
            print(f"âš ï¸ Error predicting performance trend: {e}")
            # ì˜¤ë¥˜ ì‹œ ì—ëŸ¬ ë°œìƒ
            raise
    
    def _predict_headcount_2026(self) -> Dict[str, Any]:
        """PyCaretì„ ì‚¬ìš©í•˜ì—¬ 2026ë…„ headcount ì˜ˆì¸¡"""
        try:
            from app.services.data_service import data_service
            from sklearn.linear_model import LinearRegression
            
            if data_service.current_data is None:
                raise ValueError("No data available for headcount prediction")
            
            # master_dataê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ current_data ì‚¬ìš©
            if hasattr(data_service, 'master_data') and data_service.master_data is not None:
                df = data_service.master_data.copy()
            else:
                df = data_service.current_data.copy()
            
            # headcountì™€ year ì»¬ëŸ¼ í™•ì¸
            if 'headcount' not in df.columns:
                raise ValueError("No headcount data available")
            
            # ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸°
            if 'year' in df.columns:
                year_col = 'year'
            elif 'eng' in df.columns:
                year_col = 'eng'
            else:
                # ì—°ë„ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì‹¤ì œ ë°ì´í„° ì‹œì‘ ì—°ë„ë¶€í„° ì¸ë±ìŠ¤ë¡œ ì—°ë„ ìƒì„±
                df['year'] = range(2021, 2021 + len(df))
                year_col = 'year'
            
            # ë°ì´í„° ì •ë¦¬
            headcount_data = df[[year_col, 'headcount']].copy()
            headcount_data.columns = ['year', 'headcount']
            
            # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ ë° ê²°ì¸¡ê°’ ì œê±°
            headcount_data['year'] = pd.to_numeric(headcount_data['year'], errors='coerce')
            headcount_data['headcount'] = pd.to_numeric(headcount_data['headcount'], errors='coerce')
            headcount_data = headcount_data.dropna()
            
            if len(headcount_data) < 2:
                raise ValueError("Insufficient headcount data for prediction")
            
            print(f"ğŸ“Š Headcount data for prediction:")
            for _, row in headcount_data.iterrows():
                print(f"   Year {int(row['year'])}: {int(row['headcount'])} people")
            
            # ì•ˆì •ì ì¸ ì˜ˆì¸¡ì„ ìœ„í•´ ìµœê·¼ íŠ¸ë Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ê³„ì‚°
            recent_data = headcount_data.tail(3)  # ìµœê·¼ 3ë…„ ë°ì´í„°ë§Œ ì‚¬ìš©
            
            if len(recent_data) >= 2:
                # ìµœê·¼ ë°ì´í„°ë¡œ ì„ í˜•íšŒê·€
                X_recent = recent_data[['year']].values
                y_recent = recent_data['headcount'].values
                
                lr_model = LinearRegression()
                lr_model.fit(X_recent, y_recent)
                
                print(f"   Recent trend coefficient (slope): {lr_model.coef_[0]:.2f}")
                print(f"   Recent trend intercept: {lr_model.intercept_:.2f}")
                
                # ê¸°ë³¸ 2026ë…„ ì˜ˆì¸¡
                prediction_year = np.array([[2026]])
                base_prediction = lr_model.predict(prediction_year)[0]
                
                # ë³´ìˆ˜ì  ì¡°ì •: ê¸‰ê²©í•œ ë³€í™” ë°©ì§€
                latest_headcount = recent_data.iloc[-1]['headcount']
                
                # ìµœëŒ€ Â±20% ë³€ë™ ì œí•œ
                max_change = latest_headcount * 0.2
                min_prediction = latest_headcount - max_change
                max_prediction = latest_headcount + max_change
                
                predicted_headcount = np.clip(base_prediction, min_prediction, max_prediction)
                predicted_headcount = max(400, round(predicted_headcount))  # ìµœì†Œ 400ëª… ë³´ì¥
            else:
                # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ìµœê·¼ ê°’ ê¸°ì¤€ìœ¼ë¡œ ë³´ìˆ˜ì  ì˜ˆì¸¡
                latest_headcount = headcount_data.iloc[-1]['headcount']
                predicted_headcount = round(latest_headcount * 1.02)  # 2% ì„±ì¥ ê°€ì •
                lr_model = None
            
            print(f"ğŸ“Š Headcount prediction for 2026: {predicted_headcount} people")
            
            # ì„±ì¥ë¥  ê³„ì‚° (ìµœê·¼ë…„ë„ ëŒ€ë¹„)
            if len(headcount_data) > 0:
                latest_headcount = headcount_data.iloc[-1]['headcount']
                growth_rate = (predicted_headcount - latest_headcount) / latest_headcount
                print(f"   Growth vs latest year: {growth_rate*100:.1f}%")
                print(f"ğŸ“Š Final headcount prediction for 2026: {predicted_headcount} people")
            else:
                growth_rate = 0
            
            return {
                "predicted_headcount": int(predicted_headcount),
                "growth_rate": float(growth_rate),
                "historical_data": headcount_data.to_dict('records'),
                "model_info": {
                    "slope": float(lr_model.coef_[0]) if lr_model else 0.0,
                    "intercept": float(lr_model.intercept_) if lr_model else 0.0,
                    "data_points": len(headcount_data),
                    "recent_data_points": len(recent_data) if 'recent_data' in locals() else len(headcount_data)
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ Error predicting headcount: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "predicted_headcount": 620,  # í˜„ì‹¤ì ì¸ ê¸°ë³¸ê°’ (í˜„ì¬ 600ëª… + ì•½ê°„ ì„±ì¥)
                "growth_rate": 0.03,  # 3% ì„±ì¥ ê°€ì •
                "historical_data": [],
                "model_info": {"error": str(e)}
            }

    def predict_wage_increase(self, model, input_data: Dict[str, float], confidence_level: float = 0.95) -> Dict[str, Any]:
        """2026ë…„ ì„ê¸ˆì¸ìƒë¥  ì˜ˆì¸¡
        
        Args:
            model: í•™ìŠµëœ ëª¨ë¸
            input_data: ì˜ˆì¸¡ì— ì‚¬ìš©í•  2025ë…„ ê²½ì œì§€í‘œ ë°ì´í„°
            confidence_level: ì‹ ë¢°êµ¬ê°„ ìˆ˜ì¤€
            
        Returns:
            2026ë…„ ì„ê¸ˆì¸ìƒë¥  ì˜ˆì¸¡ ê²°ê³¼
        """
        
        try:
            # ModelingServiceì—ì„œ 2025ë…„ ë°ì´í„° í™•ì¸
            from app.services.modeling_service import modeling_service
            
            # input_dataê°€ ì—†ê³  modeling_serviceì— 2025ë…„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if not input_data and hasattr(modeling_service, 'prediction_data') and modeling_service.prediction_data is not None:
                # 2025ë…„ ë°ì´í„° ì‚¬ìš©
                print("ğŸ“Š Using 2025 data from modeling service for 2026 prediction")
                model_input = modeling_service.prediction_data.iloc[[0]]  # ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©
                
                # ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ì„ê¸ˆ ê´€ë ¨ ì»¬ëŸ¼ ëª¨ë‘ ì œê±°
                wage_columns_to_remove = [
                    'wage_increase_total_sbl', 'wage_increase_mi_sbl', 'wage_increase_bu_sbl',
                    'wage_increase_baseup_sbl', 'Base-up ì¸ìƒë¥ ', 'ì„±ê³¼ì¸ìƒë¥ ', 'ì„ê¸ˆì¸ìƒë¥ ',
                    'wage_increase_total_group', 'wage_increase_mi_group', 'wage_increase_bu_group'
                ]
                model_input = model_input.drop(columns=wage_columns_to_remove, errors='ignore')
            else:
                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                model_input = self._prepare_model_input(input_data)
            
            # PyCaretì˜ predict_model ì‚¬ìš©
            try:
                from pycaret.regression import predict_model
                predictions_df = predict_model(model, data=model_input)
                # 'prediction_label' ì»¬ëŸ¼ì—ì„œ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
                if 'prediction_label' in predictions_df.columns:
                    prediction = predictions_df['prediction_label'].iloc[0]
                elif 'Label' in predictions_df.columns:
                    prediction = predictions_df['Label'].iloc[0]
                else:
                    # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì´ ì˜ˆì¸¡ê°’ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                    prediction = predictions_df.iloc[0, -1]
            except Exception as e:
                logging.warning(f"PyCaret predict_model failed, using direct prediction: {e}")
                # í´ë°±: ì§ì ‘ ì˜ˆì¸¡ ì‹œë„
                prediction = model.predict(model_input)[0]
            
            # PyCaret ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            predicted_headcount = round(float(prediction))
            
            # í˜„ì¬ headcount ëŒ€ë¹„ ì„±ì¥ë¥  ê³„ì‚°
            from app.services.data_service import data_service
            growth_rate = 0.0
            
            if data_service.current_data is not None and 'headcount' in data_service.current_data.columns:
                current_headcount_data = data_service.current_data['headcount'].dropna()
                if len(current_headcount_data) > 0:
                    latest_headcount = current_headcount_data.iloc[-1]
                    growth_rate = (predicted_headcount - latest_headcount) / latest_headcount
                    print(f"ğŸ“Š PyCaret model prediction: {predicted_headcount} people")
                    print(f"ğŸ“Š Growth vs latest year ({latest_headcount}): {growth_rate*100:.1f}%")
            
            # headcount ì˜ˆì¸¡ ì •ë³´ êµ¬ì„±
            headcount_prediction = {
                "predicted_headcount": int(predicted_headcount),
                "growth_rate": float(growth_rate),
                "historical_data": [],
                "model_info": {
                    "model_type": "PyCaret ML Model",
                    "features_used": len(model_input.columns)
                }
            }
            
            # PyCaret ëª¨ë¸ì˜ ì›ë³¸ ì˜ˆì¸¡ê°’ ì‚¬ìš©
            print(f"ğŸ” Final ML model prediction: {predicted_headcount} people for 2026")
            
            # headcount ì˜ˆì¸¡ì˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
            try:
                from pycaret.regression import get_config
                X_train = get_config('X_train')
                y_train = get_config('y_train')
                
                if X_train is not None and y_train is not None:
                    train_predictions = model.predict(X_train)
                    residuals = y_train - train_predictions
                    residual_std = np.std(residuals)
                    
                    from scipy import stats
                    alpha = 1 - confidence_level
                    z_score = stats.norm.ppf(1 - alpha/2)
                    margin_error = z_score * residual_std
                    
                    confidence_interval = [
                        int(max(0, predicted_headcount - margin_error)),
                        int(predicted_headcount + margin_error)
                    ]
                else:
                    # PyCaret configê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì‹ ë¢°êµ¬ê°„ (Â±10%)
                    confidence_interval = [
                        int(predicted_headcount * 0.9),
                        int(predicted_headcount * 1.1)
                    ]
            except:
                confidence_interval = [
                    int(predicted_headcount * 0.9),
                    int(predicted_headcount * 1.1)
                ]
            
            return {
                "message": "Headcount prediction completed",
                "prediction": predicted_headcount,  # headcount ì˜ˆì¸¡ê°’
                "confidence_interval": confidence_interval,
                "confidence_level": confidence_level,
                "input_variables": input_data,
                "prediction_date": datetime.now().strftime("%Y-%m-%d"),
                "model_type": type(model).__name__,
                "headcount_prediction": headcount_prediction  # ìƒì„¸ ì •ë³´
            }
            
        except Exception as e:
            logging.error(f"Prediction failed: {str(e)}")
            raise Exception(f"Prediction failed: {str(e)}")
    
    def get_scenario_templates(self) -> List[Dict[str, Any]]:
        """ì‹œë‚˜ë¦¬ì˜¤ í…œí”Œë¦¿ ëª©ë¡ ë°˜í™˜"""
        
        templates = []
        for key, template in self.scenario_templates.items():
            templates.append({
                "id": key,
                "name": template["name"],
                "description": template["description"],
                "variables": template["variables"]
            })
        
        return templates
    
    def get_available_variables(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜ ëª©ë¡ê³¼ ì •ì˜ ë°˜í™˜"""
        
        variables = []
        current_values = {}
        
        for key, definition in self.variable_definitions.items():
            variables.append({
                "name": key,
                "display_name": definition["name"],
                "description": definition["description"],
                "min_value": definition["min_value"],
                "max_value": definition["max_value"],
                "unit": definition["unit"],
                "current_value": definition["current_value"]
            })
            current_values[key] = definition["current_value"]
        
        return {
            "variables": variables,
            "current_values": current_values
        }
    
    def get_economic_indicators(self) -> Dict[str, Any]:
        """ì£¼ìš” ê²½ì œ ì§€í‘œ ë°˜í™˜"""
        
        # ì‹¤ì œ ë°ì´í„°ë‚˜ ì™¸ë¶€ APIì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í™•ì¥ ê°€ëŠ¥
        return {
            "indicators": {
                "current_inflation": 2.5,
                "current_gdp_growth": 2.8,
                "current_unemployment": 3.2,
                "current_wage_growth": 3.5,
                "last_year_wage_growth": 3.8,
                "industry_average": 3.2,
                "public_sector_average": 2.9
            },
            "last_updated": datetime.now().strftime("%Y-%m-%d")
        }
    
    def perform_scenario_analysis(self, model, scenarios: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰"""
        
        results = []
        
        for scenario in scenarios:
            try:
                prediction_result = self.predict_wage_increase(
                    model,
                    scenario["variables"]
                )
                
                results.append({
                    "scenario_name": scenario.get("scenario_name", "Custom"),
                    "prediction": prediction_result["prediction"],
                    "confidence_interval": prediction_result["confidence_interval"],
                    "variables": scenario["variables"]
                })
                
            except Exception as e:
                logging.error(f"Scenario analysis failed for {scenario.get('scenario_name')}: {str(e)}")
                results.append({
                    "scenario_name": scenario.get("scenario_name", "Custom"),
                    "error": str(e)
                })
        
        return results
    
    def perform_sensitivity_analysis(self, model, base_variables: Dict[str, float], 
                                    target_variable: str, value_range: List[float]) -> Dict[str, Any]:
        """ë¯¼ê°ë„ ë¶„ì„ ìˆ˜í–‰"""
        
        results = []
        
        for value in value_range:
            test_variables = base_variables.copy()
            test_variables[target_variable] = value
            
            try:
                prediction_result = self.predict_wage_increase(model, test_variables)
                results.append({
                    "variable_value": value,
                    "prediction": prediction_result["prediction"]
                })
            except Exception as e:
                logging.error(f"Sensitivity analysis failed for {target_variable}={value}: {str(e)}")
                results.append({
                    "variable_value": value,
                    "error": str(e)
                })
        
        return {
            "target_variable": target_variable,
            "base_value": base_variables.get(target_variable),
            "results": results
        }
    
    def get_trend_data(self) -> Dict[str, Any]:
        """íŠ¸ë Œë“œ ë°ì´í„° ë°˜í™˜"""
        
        try:
            # ì›ë³¸ master_data íŒŒì¼ ë¡œë“œ
            import pickle
            import os
            
            master_data_path = os.path.join(os.path.dirname(__file__), '../../data/master_data.pkl')
            
            if os.path.exists(master_data_path):
                with open(master_data_path, 'rb') as f:
                    data = pickle.load(f)
                    # dataê°€ dictì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
                    if isinstance(data, dict):
                        if 'data' in data:
                            df = data['data']
                        else:
                            df = pd.DataFrame(data)
                    else:
                        df = data
                print(f"âœ… Loaded original master_data from {master_data_path}")
            elif data_service.current_data is not None:
                df = data_service.current_data.copy()
                print("âš ï¸ Using current_data (may contain augmented data)")
            else:
                df = None
            
            if df is not None:
                # íƒ€ê²Ÿ ì»¬ëŸ¼ ì°¾ê¸° (headcount ë°ì´í„°)
                target_col = 'headcount'
                if target_col not in df.columns:
                    # ë‹¤ë¥¸ ê°€ëŠ¥í•œ headcount ì»¬ëŸ¼ë“¤ ì‹œë„
                    for col in ['ì •ì›', 'employee_count', 'total_headcount']:
                        if col in df.columns:
                            target_col = col
                            break
                
                # year ë˜ëŠ” eng ì»¬ëŸ¼ ì°¾ê¸°
                year_col = 'year' if 'year' in df.columns else 'eng' if 'eng' in df.columns else None
                
                if target_col in df.columns and year_col:
                    # ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš© (master_dataëŠ” ì´ë¯¸ ì›ë³¸)
                    yearly_data = df.groupby(year_col)[target_col].first().dropna()
                    
                    # ê³¼ê±° ë°ì´í„° í¬ë§·íŒ…
                    # Headcount ì—°ë„ë³„ ë°ì´í„°
                    historical_data = []
                    
                    for year, value in yearly_data.items():
                        if pd.notna(value):
                            # headcountëŠ” ì ˆëŒ€ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            display_value = int(float(value))
                            input_year = int(year)  # ì…ë ¥ ë°ì´í„° ì—°ë„
                            prediction_year = input_year + 1  # ì˜ˆì¸¡ ëŒ€ìƒ ì—°ë„
                            
                            # 2021ë…„ ë°ì´í„° â†’ 2022ë…„ ì˜ˆì¸¡, 2022ë…„ ë°ì´í„° â†’ 2023ë…„ ì˜ˆì¸¡ ...
                            data_point = {
                                "year": prediction_year,  # ì˜ˆì¸¡ ëŒ€ìƒ ì—°ë„ë¡œ í‘œì‹œ
                                "value": display_value,
                                "type": "historical",
                                "input_year": input_year  # ì°¸ì¡°ìš©
                            }
                            
                            historical_data.append(data_point)
                    
                    # 2026ë…„ ì˜ˆì¸¡ ë°ì´í„° ì¶”ê°€ (ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°)
                    # ì´ë¯¸ 2026ë…„ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    has_2026 = any(d.get('year') == 2026 for d in historical_data)
                    
                    from app.services.modeling_service import modeling_service
                    if modeling_service.current_model and not has_2026:
                        try:
                            # 2025ë…„ ë°ì´í„°ë¡œ PyCaret ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
                            # 2025ë…„ í–‰(ë§ˆì§€ë§‰ í–‰)ì˜ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
                            year_2025_data = df[df[year_col] == 2025]
                            
                            if len(year_2025_data) > 0:
                                # 2025ë…„ ë°ì´í„°ì—ì„œ feature ê°’ë“¤ ì¶”ì¶œ
                                row_2025 = year_2025_data.iloc[0]
                                feature_columns = [col for col in df.columns if col not in ['headcount', year_col]]
                                
                                model_input = {}
                                for col in feature_columns:
                                    value = pd.to_numeric(row_2025[col], errors='coerce')
                                    if pd.notna(value):
                                        model_input[col] = value
                                    else:
                                        model_input[col] = 0.0
                                        
                                print(f"âœ… Using 2025 data for prediction: {list(model_input.keys())[:5]}...")
                            else:
                                # 2025ë…„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                                model_input = {
                                    'operating_income': 5.2,
                                    'ev_growth_gl': 8.5,
                                    'exchange_rate_change_krw': 2.3,
                                    'labor_costs': 4.8,
                                    'v_growth_gl': 7.2
                                }
                                print(f"âš ï¸ No 2025 data found, using default values")
                            
                            # PyCaret ëª¨ë¸ë¡œ 2026ë…„ headcount ì˜ˆì¸¡
                            prediction_result = self.predict_wage_increase(
                                modeling_service.current_model,
                                model_input,
                                confidence_level=0.95
                            )
                            
                            # ì˜ˆì¸¡ê°’ ê²€ì¦
                            pred_value = prediction_result["prediction"]
                            base_up = prediction_result.get("base_up_rate", 0)
                            perf = prediction_result.get("performance_rate", 0)
                            
                            # headcount ì˜ˆì¸¡ê°’ì€ ì ˆëŒ€ê°’ì´ë¯€ë¡œ ì •ìƒ ë²”ìœ„ ì²´í¬ ìˆ˜ì •
                            # ì˜ˆì¸¡ê°’ì´ 0ë³´ë‹¤ ì‘ê±°ë‚˜ ë„ˆë¬´ í° ê²½ìš°ë§Œ ë¹„ì •ìƒìœ¼ë¡œ ì²˜ë¦¬
                            if pred_value < 0 or pred_value > 10000:
                                print(f"âš ï¸ Abnormal headcount prediction value: {pred_value}")
                                raise ValueError(f"Abnormal headcount prediction: {pred_value}")
                            
                            # headcount ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€ (ì ˆëŒ€ê°’ìœ¼ë¡œ ì‚¬ìš©)
                            prediction_data = {
                                "year": 2026,
                                "value": int(round(pred_value)),  # headcountëŠ” ì ˆëŒ€ê°’
                                "type": "prediction",
                                "input_year": 2025  # 2025ë…„ ë°ì´í„°ë¡œ ì˜ˆì¸¡
                            }
                            historical_data.append(prediction_data)
                            
                            print(f"âœ… Added 2026 headcount prediction: {prediction_data['value']}ëª… (from 2025 data)")
                        except Exception as e:
                            print(f"âš ï¸ Could not generate prediction: {e}")
                            # ì˜¤ë¥˜ ì‹œ ML ì˜ˆì¸¡ê°’ì„ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                            pass
                    
                    return {
                        "message": "Trend data retrieved successfully",
                        "trend_data": historical_data,
                        "baseup_data": baseup_data if 'baseup_data' in locals() else [],
                        "chart_config": {
                            "title": "ì¸ì› ìˆ˜ ì¶”ì´ ë° 2026ë…„ ì˜ˆì¸¡",
                            "y_axis_label": "ì¸ì› ìˆ˜ (ëª…)",
                            "x_axis_label": "ì—°ë„"
                        }
                    }
            
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
            return {
                "message": "No trend data available",
                "trend_data": [],
                "chart_config": {
                    "title": "ì¸ì› ìˆ˜ ì¶”ì´",
                    "y_axis_label": "ì¸ì› ìˆ˜ (ëª…)",
                    "x_axis_label": "ì—°ë„"
                }
            }
            
        except Exception as e:
            logging.error(f"Failed to get trend data: {str(e)}")
            return {
                "message": f"Error: {str(e)}",
                "trend_data": [],
                "chart_config": {}
            }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
dashboard_service = DashboardService()
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
import warnings
import io
import sys
from contextlib import redirect_stdout, redirect_stderr
import logging

# PyCaret ë¼ì´ë¸ŒëŸ¬ë¦¬ import with error handling
try:
    from pycaret.regression import (
        setup, compare_models, create_model, tune_model, 
        finalize_model, predict_model, evaluate_model, 
        pull, get_config
    )
    PYCARET_AVAILABLE = True
except ImportError:
    PYCARET_AVAILABLE = False
    logging.warning("PyCaret not available. Modeling functionality will be limited.")

from app.services.data_service import data_service

class ModelingService:
    def __init__(self):
        self.current_experiment = None
        self.current_model = None
        self.model_results = None
        self.compared_models = None  # ë¹„êµëœ ëª¨ë¸ë“¤
        self.is_setup_complete = False
        self.feature_names = None  # Store feature names for prediction
        
        # ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        self.small_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt']
        self.medium_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt', 'rf', 'gbr']
        self.large_data_models = ['lr', 'ridge', 'lasso', 'en', 'dt', 'rf', 'gbr', 'xgboost', 'lightgbm']
    
    def check_pycaret_availability(self) -> bool:
        """PyCaret ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return PYCARET_AVAILABLE
    
    def get_optimal_settings(self, data_size: int) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ì„¤ì • ë°˜í™˜"""
        if data_size < 30:
            return {
                'train_size': 0.9,
                'cv_folds': 2 if data_size < 15 else 3,  # ë§¤ìš° ì‘ì€ ë°ì´í„°ëŠ” 2-fold
                'models': self.small_data_models,
                'normalize': False if data_size < 15 else True,  # ë§¤ìš° ì‘ì€ ë°ì´í„°ëŠ” ì •ê·œí™” ì•ˆí•¨
                'transformation': False,
                'remove_outliers': False,
                'feature_selection': False,
                'n_features_to_select': 0.8
            }
        elif data_size < 100:
            return {
                'train_size': 0.8,
                'cv_folds': 5,
                'models': self.medium_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.7
            }
        else:
            return {
                'train_size': 0.7,
                'cv_folds': 10,
                'models': self.large_data_models,
                'normalize': True,
                'transformation': True,
                'remove_outliers': True,
                'feature_selection': True,
                'n_features_to_select': 0.6
            }
    
    def prepare_data_for_modeling(self, target_column: Optional[str] = None) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        if data_service.current_data is None:
            raise ValueError("No data loaded for modeling")
        
        df = data_service.current_data.copy()
        
        # data_serviceì—ì„œ ì„¤ì •ëœ ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        model_config = data_service.get_model_config()
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ê²°ì • (ì¸ìë¡œ ë°›ì€ ê²ƒ ìš°ì„ , ì—†ìœ¼ë©´ ìë™ ê°ì§€ëœ ê²ƒ ì‚¬ìš©)
        if target_column is None:
            target_column = model_config.get('target_column')
            if target_column is None:
                # ë§ˆì§€ë§‰ ì»¬ëŸ¼ì„ íƒ€ê²Ÿìœ¼ë¡œ ê°€ì •
                target_column = df.columns[-1]
                logging.info(f"No target column specified, using last column: {target_column}")
        
        # ê¸°ë³¸ ë°ì´í„° ì •ë¦¬
        info = {
            'original_shape': df.shape,
            'target_column': target_column,
            'numeric_columns': [],
            'categorical_columns': [],
            'dropped_columns': [],
            'year_column': model_config.get('year_column'),
            'feature_columns': model_config.get('feature_columns', [])
        }
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        if target_column not in df.columns:
            raise ValueError(f"Target column '{target_column}' not found in data")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì— ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±° (2025ë…„ ì˜ˆì¸¡ ëŒ€ìƒ ë°ì´í„° ì œì™¸)
        initial_rows = len(df)
        df = df.dropna(subset=[target_column])
        removed_rows = initial_rows - len(df)
        
        if removed_rows > 0:
            info['removed_target_missing'] = removed_rows
            print(f"ğŸ“Š Removed {removed_rows} rows with missing target values (likely future prediction data)")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        if len(df) < 5:
            raise ValueError(f"Insufficient training data: only {len(df)} rows with valid target values")
        
        # ìµœì†Œí•œì˜ ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰ (PyCaretì´ ë‚˜ë¨¸ì§€ë¥¼ ì²˜ë¦¬)
        # '-' ê°’ì„ NaNìœ¼ë¡œ ë³€í™˜ (PyCaretì´ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡)
        df = df.replace(['-', ''], np.nan)
        
        # ì—°ë„ ì»¬ëŸ¼ ì œê±° (data_serviceì—ì„œ ì‹ë³„ëœ ê²ƒ ì‚¬ìš©)
        if info['year_column'] and info['year_column'] in df.columns:
            if info['year_column'] != target_column:
                df = df.drop(columns=[info['year_column']])
                info['dropped_columns'].append(info['year_column'])
                print(f"ğŸ“Š Removed year column: {info['year_column']}")
        else:
            # ë°±ì—…: ìˆ˜ë™ìœ¼ë¡œ ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸°
            year_columns = ['year', 'Year', 'YEAR', 'ë…„ë„', 'ì—°ë„']
            for year_col in year_columns:
                if year_col in df.columns and year_col != target_column:
                    df = df.drop(columns=[year_col])
                    info['dropped_columns'].append(year_col)
                    print(f"ğŸ“Š Removed year column: {year_col}")
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ìˆ«ìí˜•ì¸ì§€ í™•ì¸
        try:
            df[target_column] = pd.to_numeric(df[target_column], errors='coerce')
            df = df.dropna(subset=[target_column])  # ë³€í™˜ ì‹¤íŒ¨í•œ í–‰ ì œê±°
        except:
            raise ValueError(f"Target column '{target_column}' must contain numeric values")
        
        # PyCaretì´ ëª¨ë“  ì»¬ëŸ¼ì„ ì²˜ë¦¬í•˜ë„ë¡ í•¨
        # ê¸°ë³¸ ì •ë³´ë§Œ ìˆ˜ì§‘
        for col in df.columns:
            if col != target_column:
                if pd.api.types.is_numeric_dtype(df[col]):
                    info['numeric_columns'].append(col)
                else:
                    info['categorical_columns'].append(col)
        
        # ìµœì¢… ì •ë¦¬
        info['final_shape'] = df.shape
        info['feature_count'] = len(df.columns) - 1
        
        return df, info
    
    def setup_pycaret_environment(
        self, 
        target_column: Optional[str] = None, 
        train_size: Optional[float] = None,
        session_id: int = 42,  # ê³ ì •ëœ ì‹œë“œê°’ ì‚¬ìš©
        preprocessing_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """PyCaret í™˜ê²½ ì„¤ì • (ì „ì²˜ë¦¬ ì˜µì…˜ í¬í•¨)"""
        
        if not self.check_pycaret_availability():
            raise RuntimeError("PyCaret is not available. Please install it first.")
        
        # ë°ì´í„° ì¤€ë¹„
        ml_data, data_info = self.prepare_data_for_modeling(target_column)
        
        # ìµœì  ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        optimal_settings = self.get_optimal_settings(len(ml_data))
        actual_train_size = train_size or optimal_settings['train_size']
        
        # ì¶œë ¥ ì–µì œë¥¼ ìœ„í•œ ì„¤ì •
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ë°ì´í„° ì²´í¬ ë””ë²„ê¹…
            print(f"ğŸ“Š Before setup - Data shape: {ml_data.shape}")
            print(f"ğŸ“Š Data types: {ml_data.dtypes.value_counts()}")
            
            # ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ê°’ ì²´í¬ ë° ìˆ˜ì •
            for col in ml_data.columns:
                if pd.api.types.is_numeric_dtype(ml_data[col]):
                    # Infinity ê°’ ì²˜ë¦¬
                    if ml_data[col].isin([np.inf, -np.inf]).any():
                        print(f"âš ï¸ Column {col} contains infinity - replacing with NaN")
                        ml_data[col] = ml_data[col].replace([np.inf, -np.inf], np.nan)
                    
                    # ë§¤ìš° í° ê°’ ìŠ¤ì¼€ì¼ë§ (ë°±ë§Œ ë‹¨ìœ„ë¡œ ë³€í™˜)
                    max_val = ml_data[col].max()
                    if pd.notna(max_val) and abs(max_val) > 1e7:
                        print(f"ğŸ“Š Column {col} has large values (max: {max_val:.2e}) - scaling down")
                        # ë°±ë§Œ ë‹¨ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
                        ml_data[col] = ml_data[col] / 1e6
                        print(f"  â†’ Scaled to max: {ml_data[col].max():.2f}M")
            
            # ëª¨ë“  ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ì „ì²˜ë¦¬ ì„¤ì • ë³‘í•©
            if preprocessing_config:
                # ì‚¬ìš©ì ì •ì˜ ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                config = preprocessing_config
            else:
                # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
                config = {
                    'imputation_type': 'simple',
                    'numeric_imputation': 'mean',
                    'categorical_imputation': 'mode',
                    'normalize': optimal_settings['normalize'],
                    'normalize_method': 'zscore' if optimal_settings['normalize'] else None,
                    'transformation': optimal_settings['transformation'],
                    'transformation_method': 'yeo-johnson' if optimal_settings['transformation'] else None,
                    'remove_outliers': optimal_settings['remove_outliers'],
                    'outliers_threshold': 0.05 if optimal_settings['remove_outliers'] else None,
                    'remove_multicollinearity': True,
                    'multicollinearity_threshold': 0.9,
                    'feature_selection': optimal_settings['feature_selection']
                }
            
            # PyCaret setup ì‹¤í–‰ (ìë™ ì „ì²˜ë¦¬ ê°•í™”)
            exp = setup(
                data=ml_data,
                target=target_column,
                session_id=session_id,
                train_size=actual_train_size,
                html=False,
                verbose=False,
                
                # ìë™ ë°ì´í„° íƒ€ì… ì¶”ë¡  ë° ì „ì²˜ë¦¬
                numeric_features=None,  # PyCaretì´ ìë™ ê°ì§€
                categorical_features=None,  # PyCaretì´ ìë™ ê°ì§€
                ignore_features=None,
                
                # ê²°ì¸¡ê°’ ì²˜ë¦¬
                imputation_type=config.get('imputation_type', 'simple'),
                numeric_imputation=config.get('numeric_imputation', 'mean'),
                categorical_imputation=config.get('categorical_imputation', 'mode'),
                
                # ì •ê·œí™”
                normalize=config.get('normalize', True),
                normalize_method=config.get('normalize_method', 'zscore'),
                
                # ë³€í™˜
                transformation=config.get('transformation', False),
                transformation_method=config.get('transformation_method', 'yeo-johnson'),
                
                # ì´ìƒì¹˜ ì œê±°
                remove_outliers=config.get('remove_outliers', False),
                outliers_threshold=config.get('outliers_threshold', 0.05),
                
                # ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
                remove_multicollinearity=config.get('remove_multicollinearity', True),
                multicollinearity_threshold=config.get('multicollinearity_threshold', 0.9),
                
                # íŠ¹ì„± ì„ íƒ
                feature_selection=config.get('feature_selection', False),
                n_features_to_select=optimal_settings.get('n_features_to_select', 0.8) if config.get('feature_selection', False) else 1.0,
                
                # CV ì „ëµ
                fold_strategy='kfold',
                fold=optimal_settings['cv_folds']
            )
            
            self.current_experiment = exp
            self.is_setup_complete = True
            
        except Exception as e:
            raise RuntimeError(f"PyCaret setup failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        # ì„¤ì • ì •ë³´ ë°˜í™˜
        return {
            'message': 'PyCaret environment setup completed successfully',
            'data_info': data_info,
            'optimal_settings': optimal_settings,
            'train_size': actual_train_size,
            'available_models': optimal_settings['models']
        }
    
    def compare_models_adaptive(self, n_select: int = 3) -> Dict[str, Any]:
        """ë°ì´í„° í¬ê¸°ì— ì ì‘ì ì¸ ëª¨ë¸ ë¹„êµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        # í˜„ì¬ ë°ì´í„° í¬ê¸° í™•ì¸
        data_size = len(data_service.current_data)
        optimal_settings = self.get_optimal_settings(data_size)
        models_to_use = optimal_settings['models']
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ë¹„êµ ì‹¤í–‰
            best_models = compare_models(
                include=models_to_use,
                sort='R2',
                n_select=min(n_select, len(models_to_use)),
                verbose=False,
                fold=3  # ë¹ ë¥¸ ë¹„êµë¥¼ ìœ„í•´ fold ìˆ˜ ì œí•œ
            )
            
            # ë‹¨ì¼ ëª¨ë¸ì´ ë°˜í™˜ëœ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if not isinstance(best_models, list):
                best_models = [best_models]
            
            # ê²°ê³¼ ì •ë³´ ì¶”ì¶œ
            comparison_results = pull()
            
            # feature names ì €ì¥
            from pycaret.regression import get_config
            X_train = get_config('X_train')
            if X_train is not None:
                self.feature_names = list(X_train.columns)
                print(f"ğŸ“Š Stored feature names: {len(self.feature_names)} features")
            
            self.model_results = {
                'best_models': best_models,
                'comparison_df': comparison_results,
                'recommended_model': best_models[0] if best_models else None
            }
            # ëª¨ë¸ ë¹„êµ í›„ì—ëŠ” current_modelì„ ì„¤ì •í•˜ì§€ ì•ŠìŒ (ëª…ì‹œì  í•™ìŠµ í•„ìš”)
            # self.current_model = best_models[0] if best_models else None
            self.compared_models = best_models  # ë¹„êµëœ ëª¨ë¸ë“¤ë§Œ ì €ì¥
            
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„ í˜• íšŒê·€ ì‚¬ìš©
            warnings.warn(f"Model comparison failed: {str(e)}. Using default linear regression.")
            
            linear_model = create_model('lr', verbose=False)  # lrì€ random_stateë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
            self.model_results = {
                'best_models': [linear_model],
                'comparison_df': None,
                'recommended_model': linear_model,
                'fallback_used': True
            }
            
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': 'Model comparison completed',
            'models_compared': len(models_to_use),
            'best_model_count': len(self.model_results['best_models']),
            'recommended_model_type': type(self.model_results['recommended_model']).__name__,
            'comparison_available': self.model_results['comparison_df'] is not None,
            'data_size_category': 'small' if data_size < 30 else 'medium' if data_size < 100 else 'large'
        }
    
    def train_specific_model(self, model_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ëª¨ë¸ í•™ìŠµ"""
        
        if not self.is_setup_complete:
            raise RuntimeError("PyCaret environment not setup. Call setup_pycaret_environment first.")
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ ìƒì„± (ëª¨ë¸ë³„ë¡œ random_state ì§€ì› ì—¬ë¶€ í™•ì¸)
            # Linear models (lr, ridge, lasso ë“±)ì€ random_stateë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
            models_without_random_state = ['lr', 'ridge', 'lasso', 'en', 'lar', 'llar', 'omp', 'br', 'ard', 'par', 'ransac', 'tr', 'huber']
            
            if model_name in models_without_random_state:
                model = create_model(model_name, verbose=False)
            else:
                model = create_model(model_name, verbose=False, random_state=42)
            
            # ëª¨ë¸ íŠœë‹ (ì„ íƒì )
            try:
                tuned_model = tune_model(model, optimize='R2', verbose=False)
            except:
                tuned_model = model
            
            # ìµœì¢… ëª¨ë¸
            try:
                final_model = finalize_model(tuned_model)
            except:
                final_model = tuned_model
            
            self.current_model = final_model
            
        except Exception as e:
            raise RuntimeError(f"Model training failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': f'Model {model_name} trained successfully',
            'model_type': type(self.current_model).__name__,
            'model_name': model_name
        }
    
    def get_model_evaluation(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ì˜ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
        
        if self.current_model is None:
            # ëª¨ë¸ ë¹„êµë§Œ í•˜ê³  í•™ìŠµí•˜ì§€ ì•Šì€ ê²½ìš° ì—ëŸ¬ ë°˜í™˜
            raise RuntimeError("No trained model available. Please train a model first after comparison.")
        
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        try:
            # ì¶œë ¥ ì–µì œ
            sys.stdout = io.StringIO()
            sys.stderr = io.StringIO()
            
            # ëª¨ë¸ í‰ê°€
            evaluate_model(self.current_model)
            evaluation_results = pull()
            
        except Exception as e:
            # í‰ê°€ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
            evaluation_results = None
            warnings.warn(f"Model evaluation failed: {str(e)}")
        finally:
            # ì¶œë ¥ ë³µì›
            sys.stdout = old_stdout
            sys.stderr = old_stderr
        
        return {
            'message': 'Model evaluation completed',
            'model_type': type(self.current_model).__name__,
            'evaluation_available': evaluation_results is not None,
            'evaluation_data': evaluation_results.to_dict() if evaluation_results is not None else None
        }
    
    def predict_with_model(self, prediction_data: Optional[pd.DataFrame] = None) -> Dict[str, Any]:
        """ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰"""
        
        if self.current_model is None:
            raise RuntimeError("No trained model available for prediction")
        
        if prediction_data is None:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                predictions = predict_model(self.current_model)
                prediction_results = pull()
                
            except Exception as e:
                raise RuntimeError(f"Prediction failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
        else:
            # ì‚¬ìš©ì ì œê³µ ë°ì´í„°ë¡œ ì˜ˆì¸¡
            try:
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                predictions = predict_model(self.current_model, data=prediction_data)
                
            except Exception as e:
                raise RuntimeError(f"Prediction with custom data failed: {str(e)}")
            finally:
                sys.stdout = old_stdout
            
            prediction_results = None
        
        return {
            'message': 'Prediction completed successfully',
            'predictions_available': predictions is not None,
            'prediction_count': len(predictions) if predictions is not None else 0,
            'predictions': predictions.to_dict(orient='records') if predictions is not None else None,
            'evaluation_metrics': prediction_results.to_dict() if prediction_results is not None else None
        }
    
    def get_modeling_status(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë¸ë§ ìƒíƒœ ë°˜í™˜"""
        return {
            'pycaret_available': self.check_pycaret_availability(),
            'environment_setup': self.is_setup_complete,
            'model_trained': self.current_model is not None,
            'models_compared': self.model_results is not None,
            'data_loaded': data_service.current_data is not None,
            'current_model_type': type(self.current_model).__name__ if self.current_model else None
        }
    
    def clear_models(self) -> Dict[str, Any]:
        """ëª¨ë“  ëª¨ë¸ ë° ì‹¤í—˜ ì´ˆê¸°í™”"""
        self.current_experiment = None
        self.current_model = None
        self.model_results = None
        self.is_setup_complete = False
        
        return {
            'message': 'All models and experiments cleared successfully'
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
modeling_service = ModelingService()
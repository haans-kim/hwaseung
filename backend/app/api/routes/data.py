from fastapi import APIRouter, File, UploadFile, HTTPException, Query
from fastapi.responses import JSONResponse
from typing import Dict, Any, Optional
from pydantic import BaseModel
import os
from app.core.config import settings
from app.services.data_service import data_service
from app.services.augmentation_service import augmentation_service

router = APIRouter()

class AugmentationRequest(BaseModel):
    method: str = 'auto'  # 'auto', 'noise', 'interpolation', 'mixup'
    factor: Optional[int] = None  # ì¦ê°• ë°°ìˆ˜
    target_size: Optional[int] = None  # ëª©í‘œ í¬ê¸°
    noise_level: float = 0.02  # ë…¸ì´ì¦ˆ ìˆ˜ì¤€
    preserve_distribution: bool = True  # ë¶„í¬ ìœ ì§€

@router.options("/upload")
async def upload_options():
    return {"message": "OK"}

@router.post("/upload")
async def upload_data(file: UploadFile = File(...)) -> Dict[str, Any]:
    """
    Excel/CSV íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ë¶„ì„
    """
    # íŒŒì¼ í¬ê¸° ê²€ì¦
    if file.size and file.size > settings.MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413, 
            detail=f"File size exceeds maximum allowed size ({settings.MAX_FILE_SIZE} bytes)"
        )
    
    # íŒŒì¼ëª… ê²€ì¦
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    if not any(file.filename.endswith(ext) for ext in settings.ALLOWED_FILE_TYPES):
        raise HTTPException(
            status_code=400,
            detail=f"File type not allowed. Allowed types: {settings.ALLOWED_FILE_TYPES}"
        )
    
    try:
        print(f"ğŸ“ Processing file: {file.filename}")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        contents = await file.read()
        print(f"ğŸ“Š File size: {len(contents)} bytes")
        
        # íŒŒì¼ ì €ì¥
        saved_path = data_service.save_uploaded_file(contents, file.filename)
        print(f"ğŸ’¾ File saved to: {saved_path}")
        
        # ë°ì´í„° ë¡œë“œ ë° ë¶„ì„
        data_info = data_service.load_data_from_file(saved_path)
        print(f"ğŸ“ˆ Data loaded: {data_info['basic_stats']['shape']}")
        
        # ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœ í™•ì¸
        validation_result = data_service.validate_data_for_modeling()
        print(f"âœ… Validation: {validation_result.get('is_valid', False)}")
        
        # ìš”ì•½ ì •ë³´ ìƒì„±
        summary = data_service.get_data_summary()
        print(f"ğŸ“‹ Summary generated: {summary['shape']}")
        
        # ëª¨ë¸ ì„¤ì • ì •ë³´ ì¶”ê°€
        model_config = data_service.get_model_config()
        
        return {
            "message": "File uploaded and processed successfully",
            "filename": file.filename,
            "file_path": saved_path,
            "data_analysis": data_info,
            "validation": validation_result,
            "summary": summary,
            "model_config": model_config
        }
        
    except Exception as e:
        print(f"âŒ Error processing file: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

@router.get("/sample")
async def get_sample_data(rows: int = Query(default=10, ge=1, le=1000)) -> Dict[str, Any]:
    """
    ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (wage_increase.xlsx íŒŒì¼ ê¸°ë°˜)
    """
    try:
        # ê¸°ì¡´ wage_increase.xlsx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        sample_file = "wage_increase.xlsx"
        if os.path.exists(sample_file):
            # ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ
            data_info = data_service.load_data_from_file(sample_file)
            sample_data = data_service.get_sample_data(rows)
            
            return {
                "message": "Sample data loaded successfully",
                "source": "wage_increase.xlsx",
                "data": sample_data["data"],
                "summary": data_service.get_data_summary(),
                "analysis": {
                    "basic_stats": data_info["basic_stats"],
                    "missing_analysis": data_info["missing_analysis"]
                }
            }
        else:
            # ìƒ˜í”Œ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê°€ìƒ ë°ì´í„° ìƒì„±
            import pandas as pd
            import numpy as np
            
            # ê°€ìƒì˜ ì„ê¸ˆ ë°ì´í„° ìƒì„±
            np.random.seed(42)
            sample_df = pd.DataFrame({
                'year': range(2014, 2024),
                'inflation_rate': np.random.normal(2.5, 1.0, 10),
                'gdp_growth': np.random.normal(2.8, 1.5, 10),
                'unemployment_rate': np.random.normal(3.5, 0.8, 10),
                'wage_increase_rate': np.random.normal(3.2, 1.2, 10),
                'productivity_index': np.random.normal(100, 10, 10)
            })
            
            return {
                "message": "Generated sample data (demo)",
                "source": "generated",
                "data": sample_df.round(2).to_dict(orient="records"),
                "shape": sample_df.shape,
                "columns": sample_df.columns.tolist()
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error loading sample data: {str(e)}")

@router.get("/current")
async def get_current_data(
    rows: int = Query(default=20, ge=1, le=1000),
    include_analysis: bool = Query(default=False)
) -> Dict[str, Any]:
    """
    í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ë°˜í™˜
    """
    try:
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data currently loaded")
        
        sample_data = data_service.get_sample_data(rows)
        summary = data_service.get_data_summary()
        
        result = {
            "message": "Current data retrieved successfully",
            "data": sample_data["data"],
            "summary": summary
        }
        
        if include_analysis and data_service.data_info:
            result["analysis"] = data_service.data_info
        
        return result
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error retrieving current data: {str(e)}")

@router.get("/validate")
async def validate_current_data() -> Dict[str, Any]:
    """
    í˜„ì¬ ë°ì´í„°ì˜ ëª¨ë¸ë§ ì¤€ë¹„ ìƒíƒœ ê²€ì¦
    """
    try:
        if data_service.current_data is None:
            raise HTTPException(status_code=404, detail="No data currently loaded")
        
        validation_result = data_service.validate_data_for_modeling()
        
        return {
            "message": "Data validation completed",
            "validation": validation_result,
            "summary": data_service.get_data_summary()
        }
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error validating data: {str(e)}")

@router.get("/info")
async def get_data_info() -> Dict[str, Any]:
    """
    ë°ì´í„° ì—…ë¡œë“œ ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜
    """
    return {
        "supported_formats": settings.ALLOWED_FILE_TYPES,
        "max_file_size_mb": settings.MAX_FILE_SIZE / 1024 / 1024,
        "upload_directory": settings.UPLOAD_DIR,
        "current_data_loaded": data_service.current_data is not None,
        "system_status": "ready"
    }

@router.delete("/current")
async def clear_current_data() -> Dict[str, Any]:
    """
    í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ì‚­ì œ
    """
    data_service.current_data = None
    data_service.data_info = None
    
    return {
        "message": "Current data cleared successfully"
    }

class DataAugmentationRequest(BaseModel):
    target_size: int = 120
    noise_factor: float = 0.02

@router.get("/status")
async def get_data_status() -> Dict[str, Any]:
    """
    ë°ì´í„° ìƒíƒœ ë° ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì •ë³´
    """
    try:
        status = data_service.get_default_data_status()
        return {
            "message": "Data status retrieved successfully",
            "status": status,
            "master_data_shape": status["master_data_shape"],
            "working_data_shape": status["working_data_shape"],
            "has_master_data": status["has_master_data"],
            "is_augmented": status["is_augmented"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting data status: {str(e)}")

@router.post("/load-default")
async def load_default_data() -> Dict[str, Any]:
    """
    ê¸°ë³¸ ë°ì´í„° ë¡œë“œ (pickle íŒŒì¼ì—ì„œ)
    """
    try:
        success = data_service._load_default_data()
        if success:
            summary = data_service.get_data_summary()
            return {
                "message": "Default data loaded successfully",
                "summary": summary,
                "loaded_from_pickle": True
            }
        else:
            raise HTTPException(status_code=404, detail="No default data available")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error loading default data: {str(e)}")

@router.post("/augment")
async def augment_data(request: AugmentationRequest) -> Dict[str, Any]:
    """
    ë°ì´í„° ì¦ê°• - ë§ˆìŠ¤í„° ë°ì´í„°ë¥¼ ë³´ì¡´í•˜ê³  ì‘ì—… ë°ì´í„°ë§Œ ì¦ê°•
    """
    try:
        if data_service.master_data is None:
            raise HTTPException(status_code=404, detail="No master data loaded for augmentation")
        
        # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        model_config = data_service.get_model_config()
        target_column = model_config.get('target_column')
        year_column = model_config.get('year_column')
        
        # ë§ˆìŠ¤í„° ë°ì´í„°ë¡œë¶€í„° ì¦ê°• (ë³µì‚¬ë³¸ ì‚¬ìš©)
        augmented_df, info = augmentation_service.smart_augment(
            df=data_service.master_data.copy(),  # ë§ˆìŠ¤í„° ë°ì´í„°ì˜ ë³µì‚¬ë³¸ ì‚¬ìš©
            target_column=target_column,
            year_column=year_column,
            target_size=request.target_size,
            method=request.method
        )
        
        # ì‘ì—… ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ (ë§ˆìŠ¤í„°ëŠ” ë³´ì¡´)
        data_service.current_data = augmented_df
        data_service.last_augmentation_info = info
        data_service._save_working_data_to_pickle()  # ì‘ì—… ë°ì´í„°ë§Œ ì €ì¥
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "message": f"Data augmented successfully using {info['method']}",
            "augmentation_info": info,
            "master_preserved": True,
            "master_shape": data_service.master_data.shape,
            "working_shape": data_service.current_data.shape,
            "summary": data_service.get_data_summary()
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error augmenting data: {str(e)}")

@router.post("/reset-to-master")
async def reset_to_master() -> Dict[str, Any]:
    """
    ì‘ì—… ë°ì´í„°ë¥¼ ë§ˆìŠ¤í„° ë°ì´í„°ë¡œ ë¦¬ì…‹
    """
    try:
        result = data_service.reset_to_master()
        return {
            "message": "Successfully reset to master data",
            **result,
            "summary": data_service.get_data_summary()
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error resetting data: {str(e)}")
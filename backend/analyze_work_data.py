#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime

def connect_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    db_path = '../data/work_history.db'
    return sqlite3.connect(db_path)

def print_basic_stats():
    """ê¸°ë³¸ í†µê³„ ì •ë³´ ì¶œë ¥"""
    conn = connect_db()
    cursor = conn.cursor()

    print("="*60)
    print("ğŸ“Š ê·¼ë¬´ ì´ë ¥ ë°ì´í„° ë¶„ì„")
    print("="*60)

    # ì „ì²´ ë ˆì½”ë“œ ìˆ˜
    cursor.execute("SELECT COUNT(*) FROM work_history")
    total_records = cursor.fetchone()[0]
    print(f"\nğŸ“Œ ì „ì²´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}")

    # ê¸°ê°„ë³„ í†µê³„
    print("\nğŸ“… ê¸°ê°„ë³„ ë°ì´í„°:")
    cursor.execute("""
        SELECT period, COUNT(*) as count,
               COUNT(DISTINCT user_id) as unique_users
        FROM work_history
        GROUP BY period
        ORDER BY period
    """)
    for row in cursor.fetchall():
        print(f"  - {row[0]}: {row[1]:,} ë ˆì½”ë“œ, {row[2]} ëª…")

    # ë¶€ì„œë³„ ì¸ì› í†µê³„
    print("\nğŸ¢ ìƒìœ„ 10ê°œ ë¶€ì„œë³„ ì¸ì›ìˆ˜:")
    cursor.execute("""
        SELECT department, COUNT(DISTINCT user_id) as user_count
        FROM work_history
        GROUP BY department
        ORDER BY user_count DESC
        LIMIT 10
    """)
    for row in cursor.fetchall():
        print(f"  - {row[0]}: {row[1]} ëª…")

    # ì§ìœ„ë³„ í†µê³„
    print("\nğŸ‘¤ ì§ìœ„ë³„ ë¶„í¬:")
    cursor.execute("""
        SELECT user_position, COUNT(DISTINCT user_id) as user_count
        FROM work_history
        GROUP BY user_position
        ORDER BY user_count DESC
    """)
    for row in cursor.fetchall():
        print(f"  - {row[0]}: {row[1]} ëª…")

    conn.close()

def analyze_work_patterns():
    """ê·¼ë¬´ íŒ¨í„´ ë¶„ì„"""
    conn = connect_db()

    print("\n" + "="*60)
    print("â° ê·¼ë¬´ íŒ¨í„´ ë¶„ì„")
    print("="*60)

    # ìš”ì¼ë³„ ê·¼ë¬´ í˜„í™©
    print("\nğŸ“… ìš”ì¼ë³„ í™œë™ í˜„í™©:")
    query = """
        SELECT weekday, COUNT(*) as activity_count,
               COUNT(DISTINCT user_id) as unique_users
        FROM work_history
        GROUP BY weekday
        ORDER BY
            CASE weekday
                WHEN 'ì›”ìš”ì¼' THEN 1
                WHEN 'í™”ìš”ì¼' THEN 2
                WHEN 'ìˆ˜ìš”ì¼' THEN 3
                WHEN 'ëª©ìš”ì¼' THEN 4
                WHEN 'ê¸ˆìš”ì¼' THEN 5
                WHEN 'í† ìš”ì¼' THEN 6
                WHEN 'ì¼ìš”ì¼' THEN 7
            END
    """
    df = pd.read_sql_query(query, conn)
    for _, row in df.iterrows():
        print(f"  - {row['weekday']}: {row['activity_count']:,} í™œë™, {row['unique_users']} ëª…")

    # ì£¼ë§ ê·¼ë¬´ì ë¶„ì„
    print("\nğŸ”´ ì£¼ë§ ê·¼ë¬´ í˜„í™©:")
    query_weekend = """
        SELECT period,
               COUNT(DISTINCT CASE WHEN weekday IN ('í† ìš”ì¼', 'ì¼ìš”ì¼') THEN user_id END) as weekend_workers,
               COUNT(DISTINCT user_id) as total_workers
        FROM work_history
        GROUP BY period
        ORDER BY period
    """
    df_weekend = pd.read_sql_query(query_weekend, conn)
    for _, row in df_weekend.iterrows():
        weekend_ratio = (row['weekend_workers'] / row['total_workers']) * 100 if row['total_workers'] > 0 else 0
        print(f"  - {row['period']}: {row['weekend_workers']}ëª… / {row['total_workers']}ëª… ({weekend_ratio:.1f}%)")

    conn.close()

def analyze_department_activity():
    """ë¶€ì„œë³„ í™œë™ ë¶„ì„"""
    conn = connect_db()

    print("\n" + "="*60)
    print("ğŸ¢ ë¶€ì„œë³„ í™œë™ ë¶„ì„")
    print("="*60)

    # ë¶€ì„œë³„ í‰ê·  í™œë™ëŸ‰
    query = """
        SELECT department,
               COUNT(DISTINCT user_id) as users,
               COUNT(*) as total_activities,
               ROUND(CAST(COUNT(*) AS FLOAT) / COUNT(DISTINCT user_id), 1) as avg_activities_per_user
        FROM work_history
        WHERE department IS NOT NULL
        GROUP BY department
        HAVING COUNT(DISTINCT user_id) >= 5
        ORDER BY avg_activities_per_user DESC
        LIMIT 15
    """

    print("\nğŸ“Š ë¶€ì„œë³„ í‰ê·  í™œë™ëŸ‰ (ì¸ì› 5ëª… ì´ìƒ):")
    df = pd.read_sql_query(query, conn)
    for _, row in df.iterrows():
        print(f"  - {row['department']}: í‰ê·  {row['avg_activities_per_user']:.1f} í™œë™/ì¸ (ì´ {row['users']}ëª…)")

    conn.close()

def analyze_user_activity():
    """ê°œì¸ë³„ í™œë™ ë¶„ì„"""
    conn = connect_db()

    print("\n" + "="*60)
    print("ğŸ‘¤ ê°œì¸ë³„ í™œë™ ë¶„ì„")
    print("="*60)

    # ê°€ì¥ í™œë°œí•œ ì‚¬ìš©ì
    query_active = """
        SELECT user_name, user_position, department,
               COUNT(*) as activity_count,
               COUNT(DISTINCT work_date) as work_days
        FROM work_history
        GROUP BY user_id, user_name, user_position, department
        ORDER BY activity_count DESC
        LIMIT 10
    """

    print("\nğŸ† ê°€ì¥ í™œë°œí•œ ì‚¬ìš©ì TOP 10:")
    df = pd.read_sql_query(query_active, conn)
    for i, row in df.iterrows():
        print(f"  {i+1}. {row['user_name']} ({row['user_position']}, {row['department']})")
        print(f"     í™œë™: {row['activity_count']:,}íšŒ, ê·¼ë¬´ì¼: {row['work_days']}ì¼")

    conn.close()

def export_summary_to_csv():
    """ì£¼ìš” ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
    conn = connect_db()

    # ë¶€ì„œë³„ í†µê³„
    dept_query = """
        SELECT department,
               period,
               COUNT(DISTINCT user_id) as user_count,
               COUNT(*) as activity_count,
               COUNT(DISTINCT work_date) as work_days
        FROM work_history
        GROUP BY department, period
        ORDER BY department, period
    """
    df_dept = pd.read_sql_query(dept_query, conn)

    # ë…„ë„ì™€ ì›” ë¶„ë¦¬
    df_dept['ë…„'] = df_dept['period'].str[:4].astype(int)
    df_dept['ì›”'] = df_dept['period'].str[5:7].astype(int)

    # period ì»¬ëŸ¼ ì œê±°í•˜ê³  ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì—´
    df_dept = df_dept[['department', 'ë…„', 'ì›”', 'user_count', 'activity_count', 'work_days']]

    # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½
    df_dept.columns = ['ì†Œì†íŒ€', 'ë…„', 'ì›”', 'ì¸ì›ìˆ˜', 'í™œë™íšŸìˆ˜', 'ê·¼ë¬´ì¼ìˆ˜']

    df_dept.to_csv('../data/department_summary.csv', index=False, encoding='utf-8-sig')
    print("\nâœ… ë¶€ì„œë³„ í†µê³„ ì €ì¥: ../data/department_summary.csv")

    # ì‚¬ìš©ìë³„ í†µê³„
    user_query = """
        SELECT user_id, user_name, user_position, department,
               period,
               COUNT(*) as activity_count,
               COUNT(DISTINCT work_date) as work_days,
               COUNT(DISTINCT CASE WHEN weekday IN ('í† ìš”ì¼', 'ì¼ìš”ì¼') THEN work_date END) as weekend_days
        FROM work_history
        GROUP BY user_id, user_name, user_position, department, period
        ORDER BY user_id, period
    """
    df_user = pd.read_sql_query(user_query, conn)

    # ë…„ë„ì™€ ì›” ë¶„ë¦¬
    df_user['ë…„'] = df_user['period'].str[:4].astype(int)
    df_user['ì›”'] = df_user['period'].str[5:7].astype(int)

    # period ì»¬ëŸ¼ ì œê±°í•˜ê³  ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì—´
    df_user = df_user[['user_id', 'user_name', 'user_position', 'department', 'ë…„', 'ì›”',
                       'activity_count', 'work_days', 'weekend_days']]

    # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½
    df_user.columns = ['ì‚¬ë²ˆ', 'ì„±ëª…', 'ì§ìœ„', 'ì†Œì†íŒ€', 'ë…„', 'ì›”', 'í™œë™íšŸìˆ˜', 'ê·¼ë¬´ì¼ìˆ˜', 'ì£¼ë§ê·¼ë¬´ì¼ìˆ˜']

    df_user.to_csv('../data/user_summary.csv', index=False, encoding='utf-8-sig')
    print("âœ… ì‚¬ìš©ìë³„ í†µê³„ ì €ì¥: ../data/user_summary.csv")

    conn.close()

def main():
    """ë©”ì¸ ë¶„ì„ ì‹¤í–‰"""
    print("\nğŸ” ê·¼ë¬´ ì´ë ¥ ë°ì´í„° ë¶„ì„ ì‹œì‘...")
    print("="*60)

    # ê¸°ë³¸ í†µê³„
    print_basic_stats()

    # ê·¼ë¬´ íŒ¨í„´ ë¶„ì„
    analyze_work_patterns()

    # ë¶€ì„œë³„ ë¶„ì„
    analyze_department_activity()

    # ê°œì¸ë³„ ë¶„ì„
    analyze_user_activity()

    # CSV ë‚´ë³´ë‚´ê¸°
    print("\n" + "="*60)
    print("ğŸ’¾ ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
    print("="*60)
    export_summary_to_csv()

    print("\nâœ¨ ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ’¡ ì¶”ê°€ ë¶„ì„ì„ ì›í•˜ì‹œë©´ analyze_work_data.py íŒŒì¼ì„ ìˆ˜ì •í•˜ê±°ë‚˜")
    print("   SQLite ë°ì´í„°ë² ì´ìŠ¤ '../data/work_history.db'ë¥¼ ì§ì ‘ ì¿¼ë¦¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()